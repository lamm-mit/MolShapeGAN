{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ad55fb5-428c-41d7-9118-b75d1c6fb058",
   "metadata": {},
   "source": [
    "# MolShapeGAN: LAMMPS simulator\n",
    "\n",
    "## Generative multiscale analysis of de novo proteome-inspired molecular structures and nanomechanical optimization using a VoxelPerceiver transformer model\n",
    "\n",
    "Zhenze Yang, Yu-Chuan Hsu, Markus J. Buehler, \"Generative multiscale analysis of de novo proteome-inspired molecular structures and nanomechanical optimization using a VoxelPerceiver transformer model,\" Journal of the Mechanics and Physics of Solids, Volume 170, January 2023, 105098.\n",
    "\n",
    "mbuehler@MIT.EDU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abdc7314",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import *\n",
    "from random import random\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from mpl_toolkits import mplot3d \n",
    "plt.style.use('seaborn-whitegrid')\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43489952",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.gridspec as gridspec\n",
    "import csv\n",
    "\n",
    "import math\n",
    "import shutil\n",
    "import statistics          \n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d0afcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import trimesh  \n",
    "import time, warnings\n",
    "from PIL import Image\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "        \n",
    "def img2vox(loc, end='png', thresh=127, im_sh=False):\n",
    "    vox = []\n",
    "    imgs = sorted(glob.glob(loc+'/*.'+end), key=lambda x: (len(x), x))\n",
    "\n",
    "    print('found',len(imgs),'images.',imgs)\n",
    "    for i in imgs:\n",
    "        new_frame = Image.open(i).convert('RGB').convert('L')\n",
    "        \n",
    "        new_frame =np.array(new_frame)\n",
    "        _, new_frame = cv2.threshold(new_frame,thresh,255,cv2.THRESH_BINARY)\n",
    "        \n",
    "        if im_sh:\n",
    "                plt.imshow(new_frame, interpolation='nearest',cmap=\"hot\")\n",
    "                plt.colorbar()\n",
    "                plt.show()\n",
    "                \n",
    "        vox.append(np.array(new_frame))\n",
    "\n",
    "    return np.array(vox)\n",
    "\n",
    "def TwoDimg23Dvox(img_,maxheight=10, invvv=False, thresh=0, \n",
    "                  normalize=False,norm_zero=False,clipvalue=0,sat=1,GaussSmoothimage=False, iblur=0, BilatSmoothimage=False, centerrep=0, darea=0, invertresult=False):\n",
    "\n",
    "   vox = []\n",
    "   print (\"Number of images: \", len (img_[:]))  \n",
    "   for imc in range (len(img_[:])):\n",
    "    img=img_[imc]\n",
    "    print (\"Considering image: \", imc)\n",
    "    if GaussSmoothimage==True:\n",
    "        print (\"smoothen using Gaussian Blur...\")\n",
    "        #Applying the blur filter\n",
    "        img = cv2.GaussianBlur(img,(5,5),0)\n",
    "        #img = cv2.bilateralFilter(img,9,75,75) \n",
    "        \n",
    "        for ij in range (iblur):\n",
    "                img = cv2.GaussianBlur(img, (3,3), 10,10)\n",
    "    if BilatSmoothimage==True:\n",
    "        print (\"smoothen using Bilat Blur...\")\n",
    "        #Applying the blur filter\n",
    "        #img = cv2.GaussianBlur(img,(5,5),0)\n",
    "        img = cv2.bilateralFilter(img,9,75,75) \n",
    "        for ij in range (iblur):\n",
    "                img = cv2.bilateralFilter(img,9,75,75) \n",
    "        \n",
    "    img =np.array(img)\n",
    "    img = np.array(img, dtype = np.float16)\n",
    "\n",
    "    #apply overall threshold - below thresh = 0, creates holes\n",
    "    img[img <thresh] = 0\n",
    "    \n",
    "    if normalize==True:\n",
    "            minval=np.amin(img[img>0])-clipvalue\n",
    "            print (\"Normalize...\", minval, np.amax(img))\n",
    "            if norm_zero: \n",
    "                print (\"Start buildup at zero...\", minval)\n",
    "                img=img-minval\n",
    "                #img[img <0] = 0\n",
    "                img=np.clip(img, 0, 255)\n",
    "                #img[img <0] = 0\n",
    "                #print (img.shape)\n",
    "                \n",
    "                #for i in range (img.shape[1]):\n",
    "                #    for j in range (img.shape[0]):\n",
    "                #        print (img[i,j])\n",
    "                #        if img[i,j]<0:\n",
    "                #            print (img[i,j])\n",
    "                \n",
    "                plt.imshow(img, interpolation='nearest',cmap=\"hot\")\n",
    "                plt.colorbar()\n",
    "                plt.show()\n",
    "                #img = [0 if a_ < 0 else a_ for a_ in img]\n",
    "            print ( np.amin(img), np.amax(img))\n",
    "        \n",
    "            img=img/np.amax(img)*255\n",
    "    \n",
    "            \n",
    "    img=img*sat\n",
    "    img[img >255] = 255\n",
    "    \n",
    "    \n",
    "    img = np.array(img, dtype = np.uint8)\n",
    "\n",
    "    #number of layers\n",
    "     \n",
    "    #here add middle SOLID PLATE\n",
    "    if darea>0:\n",
    "        #img=Image.fromarray(img)\n",
    "        \n",
    "        #thresh_i = cv2.adaptiveThreshold(img,255,cv2.ADAPTIVE_THRESH_MEAN_C  ,cv2.THRESH_BINARY_INV,5,2)\n",
    "        _, thresh_i = cv2.threshold(img,80,255,cv2.THRESH_BINARY)\n",
    "        plt.imshow(thresh_i, interpolation='nearest',cmap=\"hot\")\n",
    "        plt.colorbar()\n",
    "        plt.show()\n",
    "\n",
    "        print (\"##remove small areas...\", darea)\n",
    "        # Filter using contour area and remove small noise\n",
    "        cnts = cv2.findContours(thresh_i, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE )\n",
    "        cnts = cnts[0] if len(cnts) == 2 else cnts[1]\n",
    "        for c in cnts:\n",
    "            area = cv2.contourArea(c)\n",
    "            #print (area)\n",
    "            if area < darea:\n",
    "                #print (\"REMOVE\")\n",
    "                cv2.drawContours(img, [c], -1, (0,0,0), -1)\n",
    "                #cv2.drawContours(img, [c], -1, (255,255,255), -1)\n",
    "        #img =np.array(img)\n",
    "\n",
    "    print (\"Image to be used...\")    \n",
    "    if invertresult:\n",
    "        print (\"INVERT\")\n",
    "        img = cv2.bitwise_not(img)\n",
    "    \n",
    "    plt.imshow(img, interpolation='nearest',cmap=\"hot\")\n",
    "    plt.colorbar()\n",
    "    plt.show()\n",
    "    print (\"start for i=\", imc)\n",
    "    \n",
    "    if invvv==True:\n",
    "      print (\"add inverse on other side\") \n",
    "      for ii in range (maxheight):\n",
    "    \n",
    "        threshold=(maxheight-ii)/(maxheight)*255\n",
    "        #new_img  = img[img<= threshold]\n",
    "        z = np.copy(img)\n",
    "        \n",
    "        z[z <threshold] = 0\n",
    "        z[z >0] = 255\n",
    "            \n",
    "        vox.append(z)\n",
    "\n",
    "    if centerrep>0:\n",
    "        print (\"adding center layer/solid!\")\n",
    "        z2 = np.copy(img)\n",
    "\n",
    "        z2[z2 >=0] = 255\n",
    "    \n",
    "        for infg in range( (centerrep)):\n",
    "             vox.append(z2)\n",
    "    \n",
    "    \n",
    "\n",
    "    for ii in range (maxheight):\n",
    "    \n",
    "        threshold=(ii/maxheight)*255\n",
    "        #new_img  = img[img<= threshold]\n",
    "        z = np.copy(img)\n",
    "        \n",
    "        z[z <threshold] = 0\n",
    "        z[z >0] = 255\n",
    "        \n",
    "            \n",
    "        vox.append(z)\n",
    "\n",
    "   return np.array(vox)\n",
    "\n",
    "def TwoDimg23Dvox_BACKUP(img,maxheight=10, invvv=False, thresh=0, normalize=False,sat=1,GaussSmoothimage=False, BilatSmoothimage=False):\n",
    "\n",
    "    if GaussSmoothimage==True:\n",
    "        print (\"smoothen using Gaussian Blur...\")\n",
    "        #Applying the blur filter\n",
    "        img = cv2.GaussianBlur(img,(5,5),0)\n",
    "        #img = cv2.bilateralFilter(img,9,75,75) \n",
    "    if BilatSmoothimage==True:\n",
    "        print (\"smoothen using Gaussian Blur...\")\n",
    "        #Applying the blur filter\n",
    "        #img = cv2.GaussianBlur(img,(5,5),0)\n",
    "        img = cv2.bilateralFilter(img,9,75,75) \n",
    "        \n",
    "    img =np.array(img)\n",
    "    #apply overall threshold - below thresh = 0, creates holes\n",
    "    img[img <thresh] = 0\n",
    "    \n",
    "    if normalize==True:\n",
    "            \n",
    "            print (\"Normalize...\", np.amin(img), np.amax(img))\n",
    "            img=img-(np.amin(img)   )\n",
    "            img[img <0] = 0\n",
    "    \n",
    "            print (  np.amax(img))\n",
    "            img=img/np.amax(img)*255\n",
    "            \n",
    "    img=img*sat\n",
    "    img[img >255] = 255\n",
    "    \n",
    "    plt.imshow(img, interpolation='nearest',cmap=\"hot\")\n",
    "    plt.colorbar()\n",
    "    plt.show()\n",
    "    print (\"start\")\n",
    "    vox = []\n",
    "    #number of layers\n",
    "     \n",
    "    \n",
    "    if invvv==True:\n",
    "      print (\"add inverse on other side\") \n",
    "      for ii in range (maxheight):\n",
    "    \n",
    "        threshold=(maxheight-ii)/(maxheight)*255\n",
    "        #new_img  = img[img<= threshold]\n",
    "        z = np.copy(img)\n",
    "        \n",
    "        z[z <threshold] = 0\n",
    "        z[z >0] = 255\n",
    "        \n",
    "        #print (ii,threshold,z )\n",
    "        \n",
    "        #   for x in range (img.shape[0]):\n",
    "        #       for y in range (img.shape[1]):\n",
    "        #           pixelint=img[y,x]\n",
    "        #           print (x,y,pixelint)\n",
    "        \n",
    "        #plt.imshow(z, interpolation='nearest')\n",
    "        #plt.show()\n",
    "            \n",
    "        vox.append(z)\n",
    "\n",
    "    for ii in range (maxheight):\n",
    "    \n",
    "        threshold=(ii/maxheight)*255\n",
    "        #new_img  = img[img<= threshold]\n",
    "        z = np.copy(img)\n",
    "        \n",
    "        z[z <threshold] = 0\n",
    "        z[z >0] = 255\n",
    "        \n",
    "        #print (ii,threshold,z )\n",
    "        \n",
    "        #   for x in range (img.shape[0]):\n",
    "        #       for y in range (img.shape[1]):\n",
    "        #           pixelint=img[y,x]\n",
    "        #           print (x,y,pixelint)\n",
    "        \n",
    "        #plt.imshow(z, interpolation='nearest')\n",
    "        #plt.show()\n",
    "            \n",
    "        vox.append(z)\n",
    "\n",
    "    return np.array(vox)\n",
    "\n",
    "\n",
    "def vox2stl(vox, loc='.', filename='', save=True, smooth=False, smooth_iter=20):\n",
    "    mesh = trimesh.voxel.ops.matrix_to_marching_cubes(vox)\n",
    "\n",
    "    if smooth:\n",
    "        print (\"Smoothing: on\")\n",
    "        \n",
    "        #mesh = trimesh.smoothing.filter_humphrey(mesh)\n",
    "        \n",
    "        #trimesh.smoothing.filter_mut_dif_laplacian(mesh, lamb=0.5, iterations=10, volume_constraint=True, laplacian_operator=None)\n",
    "        mesh=  trimesh.smoothing.filter_mut_dif_laplacian(mesh, lamb=0.85, iterations=smooth_iter)\n",
    "        \n",
    "\n",
    "    mesh.rezero()\n",
    "    if save:\n",
    "\n",
    "        from time import strftime\n",
    "        stamp = strftime(\"%m_%d_%H_%M\")\n",
    "        os.makedirs(loc, exist_ok=True)\n",
    "        mesh.export(loc+'/'+filename+'_'+stamp+'.stl')\n",
    "        print('save stl model to {}'.format(loc+'/'+filename+'_'+stamp+'.stl'))\n",
    "\n",
    "# here are four basic logical operations that can be applied to voxels\n",
    "\n",
    "# return a vox that vox1 OR vox2 exist (A||B) \n",
    "def union(vox1, vox2): \n",
    "    return np.logical_or(vox1, vox2)\n",
    "\n",
    "# return a vox that EITHER only vox1 OR vox2 exists (A||B-A&&B)\n",
    "def xor(vox1, vox2):\n",
    "    return np.logical_xor(vox1, vox2)\n",
    "\n",
    "# return a vox that both vox1 exists BUT vox2 does not (A-B) \n",
    "def substraction(vox1, vox2):\n",
    "    return np.logical_xor(np.logical_or(vox1, vox2), vox2)\n",
    "\n",
    "# return a vox that vox1 and vox2 BOTH exist (A&&B) \n",
    "def intersection(vox1, vox2):\n",
    "    return np.logical_and(vox1, vox2)\n",
    "\n",
    "# return a vox inverse to the original (B!=A) \n",
    "def inverse(vox):\n",
    "    return np.logical_not(vox)\n",
    "\n",
    "def repeat(vox, repeatance_array):\n",
    "    return np.tile(vox, repeatance_array)*1\n",
    "\n",
    "\n",
    "def vox2img(vox, loc='.', filename=''):\n",
    "    \n",
    "    from time import strftime\n",
    "    stamp = strftime(\"%m_%d_%H_%M\")\n",
    "    os.makedirs(loc+'/'+filename+'_img/', exist_ok=True)\n",
    "    for i in range(vox.shape[0]):\n",
    "        temp_img=vox[i]\n",
    "        plt.imsave(loc+'/'+filename+'_img/'+filename+'_'+stamp+'_'+str(i)+'.png', temp_img, cmap='gray')\n",
    "        from IPython import display\n",
    "        display.clear_output(wait=True)\n",
    "        plt.imshow(temp_img, cmap='gray')    \n",
    "        plt.axis('off')\n",
    "        plt.title(str(i))\n",
    "        plt.show()\n",
    "    \n",
    "    print('save stl model as a stack of images into {}'.format(loc+'/'+filename+'_img/'))\n",
    "\n",
    "def vox2npy(vox, loc='.', filename=''):\n",
    "    from time import strftime\n",
    "    stamp = strftime(\"%m_%d_%H_%M\")\n",
    "    os.makedirs(loc, exist_ok=True)\n",
    "    np.save(loc+'/'+filename+'_'+stamp+'.npy', vox)\n",
    "    print('save stl model as a 3D array to {}'.format(loc+'/'+filename+'_'+stamp+'.npy'))\n",
    "\n",
    "def npy2vox(filename=''):\n",
    "    return np.load(filename)*1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceffca34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_stl2point (loc='./', fname='voxel_0_tester_0_06_11_05_45.stl', \n",
    "                    size=64, sizevoxel =1 , reorient=True, \n",
    "                    threshold=0.8 , scaled=False, show_on=True ):\n",
    "    im, STLname=stl2vox(loc,fname, size=size, sizevoxel =sizevoxel , reorient=reorient, threshold=threshold, scaled=scaled  )\n",
    "    print (\"Voxel tensor shape: \", im.shape)\n",
    "    \n",
    "    fig = plt.figure(figsize=(6, 6))\n",
    "    gs = gridspec.GridSpec(1, 1)\n",
    "    gs.update(wspace=0.05, hspace=0.05)\n",
    "\n",
    "    x, y, z = im.nonzero() #returns indixes or coordinates of all nonzero entries...\n",
    "    \n",
    "    if show_on:\n",
    "        ax = plt.subplot(gs[0], projection='3d')\n",
    "        ax.scatter(x, y, z, zdir='z', c='red', marker='s', s=2)\n",
    " \n",
    "        plt.show()\n",
    "\n",
    "        plt.scatter (x, z, c='red', marker='s', s=2)\n",
    "        #plt.axis('square')\n",
    "        plt.axis('equal')\n",
    "        plt.xlabel('x')\n",
    "        plt.ylabel('z')    \n",
    "        plt.show()\n",
    "\n",
    "        plt.scatter (y, z, c='red', marker='s', s=2)\n",
    "        #plt.axis('square')\n",
    "        plt.axis('equal')\n",
    "        plt.xlabel('y')\n",
    "        plt.ylabel('z')\n",
    "        plt.show()\n",
    "\n",
    "        plt.scatter (x, y, c='red', marker='s', s=2)\n",
    "        #plt.axis('square')\n",
    "        plt.axis('equal')\n",
    "        plt.xlabel('x')\n",
    "        plt.ylabel('y')\n",
    "\n",
    "        plt.show()\n",
    "    \n",
    "    \n",
    "    dx=max(x)-min(x)\n",
    "    dy=max(y)-min(y)\n",
    "    dz=max(z)-min(z)\n",
    "    \n",
    "    print (f\"Max/min x {max(x)}, {min (x)}; Max/min y {max(y)}, {min (y)}; Max/min z {max(z)}, {min (z)}\")\n",
    "    print (f\"(dx,dy,dz)=({dx}, {dy}, {dz})\")\n",
    "    \n",
    "    \n",
    "    return im, [x, y, z], [dx, dy, dz], STLname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0f5066",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.decomposition import PCA\n",
    "    \n",
    "\n",
    "def reorient_STL_largestaxis_OLD (fnamein, fnameout):\n",
    "    stl = mesh.Mesh.from_file(fnamein)\n",
    "\n",
    "\n",
    "    # method: PCA to find the principal component as the long axis. This may fail for some weird geometries...\n",
    "    stl.vectors = stl.vectors - np.mean(stl.vectors, axis=0)\n",
    "    stl.update_centroids()\n",
    "    pca=PCA(2)\n",
    "    pca.fit(stl.centroids)\n",
    "    long_vector=pca.components_[0]\n",
    "\n",
    "\n",
    "    # In[16]:\n",
    "\n",
    "\n",
    "    stl.rotate([1, 0, 0], math.acos(long_vector[0]/np.linalg.norm(long_vector)))\n",
    "    stl.rotate([0, 1, 0], math.acos(long_vector[1]/np.linalg.norm(long_vector)))\n",
    "    stl.rotate([0, 0, 1], math.acos(long_vector[2]/np.linalg.norm(long_vector)))\n",
    "    \n",
    "    #stl.rotate([0, 1, 0], math.radians(90))\n",
    "    #stl.rotate([0, 1, 0], math.radians(-90))\n",
    "    stl.rotate([0, 0, 1], math.radians(90))\n",
    "    \n",
    "    # stl.vectors = stl.vectors - stl.vectors[0]\n",
    "    # stl.update_centroids()\n",
    "    print (\"saving rotated STL under: \", fnameout)\n",
    "    stl.save(fnameout)\n",
    "    \n",
    "    return fnameout\n",
    "\n",
    "\n",
    "\n",
    "def reorient_STL_largestaxis (fnamein, fnameout):\n",
    "    stl = mesh.Mesh.from_file(fnamein)\n",
    "\n",
    "     # method: PCA to find the principal component as the long axis. This may fail for some weird geometries...\n",
    "\n",
    "     \n",
    "    pca=PCA(2)\n",
    "    pca.fit(stl.centroids)\n",
    "    long_vector=pca.components_[0]\n",
    "\n",
    "    axis=np.cross(long_vector, [0,0,1])\n",
    "    stl.rotate(axis, -math.acos(np.dot(long_vector, [0,0,1])/np.linalg.norm(long_vector)))\n",
    "    stl.vectors = np.round(stl.vectors, 4)\n",
    "    stl.update_centroids()\n",
    "    #stl.save(fname+'_after.stl')\n",
    "\n",
    "    print (\"saving rotated STL under: \", fnameout)\n",
    "    stl.save(fnameout)\n",
    "    \n",
    "    return fnameout\n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589d500a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0caa7272",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trimesh.voxel import creation\n",
    "#from mesh_to_sdf import mesh_to_voxels\n",
    "import scipy.ndimage as nd\n",
    "import trimesh\n",
    "import skimage\n",
    "from stl import mesh as stlmesh\n",
    "from stl import mesh\n",
    "#!pip install numpy-stl\n",
    "def find_mins_maxs(obj):\n",
    "    minx = obj.x.min()\n",
    "    maxx = obj.x.max()\n",
    "    miny = obj.y.min()\n",
    "    maxy = obj.y.max()\n",
    "    minz = obj.z.min()\n",
    "    maxz = obj.z.max()\n",
    "    return minx, maxx, miny, maxy, minz, maxz\n",
    "\n",
    "def stl2vox(loc='', filename='', size=64, sizevoxel=1., reorient=False, \n",
    "            threshold=0.5, scaled=False): #scaled = True = will rescale to unit cube first then transform \n",
    "    \n",
    "    #mesh = trimesh.voxel.ops.matrix_to_marching_cubes(vox)\n",
    "\n",
    "    if scaled==False:\n",
    "        if reorient:\n",
    "            print (\"Reorient along longest axis...\")\n",
    "            filenamenew='reor_'+filename\n",
    "            reorient_STL_largestaxis ( loc+filename, loc+filenamenew)\n",
    "\n",
    "            filename=filenamenew\n",
    "\n",
    "        print (\"Loading...\", loc+filename)\n",
    "        mesh = trimesh.load_mesh(loc+filename)\n",
    "        #mesh = trimesh.scale_to_unit_sphere(mesh)\n",
    "        #voxel_grid=creation.local_voxelize(mesh,mesh.centroid, mesh.extents.max() / (2*size), size, fill=True)\n",
    "        #tmp_raw=voxel_grid.encoding.data\n",
    "\n",
    "\n",
    "\n",
    "        #mesh (trimesh.Trimesh) – Source geometry\n",
    "        #point ((3, ) float) – Point in space to voxelize around\n",
    "        #pitch (float) – Side length of a single voxel cube\n",
    "        #radius (int) – Number of voxel cubes to return in each direction.\n",
    "        #kwargs (parameters to pass to voxelize_subdivide) –\n",
    "        #print (mesh.centroid)\n",
    "\n",
    "        voxels=creation.local_voxelize (mesh, mesh.centroid, sizevoxel, size, fill=True).encoding.data*1.\n",
    "        voxels[voxels <= threshold] = 0\n",
    "\n",
    "        #voxels = nd.zoom(voxels, ( size/voxels.shape[0],size/voxels.shape[1],size/voxels.shape[2]   ), \n",
    "        #                 mode='constant', order=0)\n",
    "\n",
    "        return voxels, filename\n",
    "\n",
    "    if scaled:\n",
    "        if reorient:\n",
    "            print (\"Reorient along longest axis...\")\n",
    "            filenamenew='reor_'+filename\n",
    "            reorient_STL_largestaxis ( loc+filename, loc+filenamenew)\n",
    "\n",
    "            filename=filenamenew\n",
    "\n",
    "\n",
    "        mesh = trimesh.load(loc+filename)\n",
    "        mesh=scale_to_unit_cube(mesh) \n",
    "       \n",
    "        voxels = creation.local_voxelize (mesh, mesh.centroid, sizevoxel, size, fill=True).encoding.data*1.\n",
    "        voxels[voxels <= threshold] = 0\n",
    "\n",
    "        voxels = nd.zoom(voxels, ( size/voxels.shape[0],size/voxels.shape[1],size/voxels.shape[2]   ), \n",
    "                         mode='constant', order=0)\n",
    "\n",
    "        # print (\"Voxel size: \",voxels.shape )\n",
    "        #return creation.voxelize (mesh, pitch=sizevoxel)\n",
    "        return voxels     , filename\n",
    "    \n",
    "def scale_to_unit_cube(mesh):\n",
    "    if isinstance(mesh, trimesh.Scene):\n",
    "        mesh = mesh.dump().sum()\n",
    "\n",
    "    vertices = mesh.vertices - mesh.bounding_box.centroid\n",
    "    #vertices *= 2 / np.max(mesh.bounding_box.extents)\n",
    "    vertices *= 1 / np.max(mesh.bounding_box.extents)\n",
    "\n",
    "    return trimesh.Trimesh(vertices=vertices, faces=mesh.faces)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f32672",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "im_res=32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23fdfceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_voxel (path):\n",
    "\n",
    "    voxels=np.load(path)\n",
    "    #voxels = nd.zoom(voxels, (.5, .5, .5), mode='constant', order=0)\n",
    "    \n",
    "    print (voxels.shape)\n",
    "    return voxels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e8189a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "v=load_voxel ('np_vox_0000_0000.npy')\n",
    "#print (v)\n",
    "plt.plot (v[32,:,20])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c6f8ae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def im_generate (im_resx, im_resy, x, y, aspect, thick, angle):\n",
    "    # Create a black image\n",
    "    img = 255*np.ones((im_resy,im_resx,3), np.uint8)\n",
    "\n",
    "    cv2.ellipse(img,  (int(x),int(y)),(int(aspect*thick),int(thick)),angle,0,360, (0,0,0) ,-1  )\n",
    "    #cv.ellipse(img,(256,256),(100,50),0,0,180,255,-1)\n",
    "    return img\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e623298a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check if pixel in material should form a material \n",
    "\n",
    "def is_material (img , i, j, thresh=0):\n",
    "    \n",
    "    flag = False \n",
    "    \n",
    "    \n",
    "    if np.any(img[i, j] >thresh): #if black == no material , can also choose threshold\n",
    "        #print (img[i, j])\n",
    "        flag=True\n",
    "        #print (flag)\n",
    "    return flag\n",
    "\n",
    "#check if pixel in material should form a material \n",
    "\n",
    "def get_material_type (img , i, j, thresh=0):\n",
    "    \n",
    "    mtype= 1\n",
    "    \n",
    "    \n",
    "    if np.any(img[i, j] >thresh): #if black == material type 2, which is soft (white inclusions are STIFF!!)\n",
    "        #print (img[i, j])\n",
    "        mtype=2\n",
    "        #print (flag)\n",
    "    return mtype\n",
    "\n",
    "\n",
    "\n",
    "def is_material_voxel (img , i, j, k, thresh=0):\n",
    "    \n",
    "    flag = False \n",
    "    \n",
    "    \n",
    "    if np.any(img[i, j, k] >thresh): #if black == no material , can also choose threshold\n",
    "        #print (img[i, j])\n",
    "        flag=True\n",
    "        #print (flag)\n",
    "    return flag\n",
    "\n",
    "#check if pixel in material should form a material \n",
    "\n",
    "def get_material_type_voxel (img , i, j, k, thresh=0):\n",
    "    \n",
    "    mtype= 1\n",
    "    \n",
    "    \n",
    "    if np.any(img[i, j, k] >thresh): #if black == material type 2, which is soft (white inclusions are STIFF!!)\n",
    "        #print (img[i, j])\n",
    "        mtype=2\n",
    "        #print (flag)\n",
    "    return mtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b85fb3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1bf88bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_result (fname):\n",
    "\n",
    "    data_list=[]\n",
    "    read_n=False\n",
    "    i=0\n",
    "    countframe=0\n",
    "    with open(fname) as f:\n",
    "        for line in f:\n",
    "                #print (i)\n",
    "                content_list = line\n",
    "                if read_n==True:\n",
    "                        if (\"ITEM:\" in content_list ):\n",
    "                            read_n=False\n",
    "                            countframe=countframe+1\n",
    "                        else:\n",
    "                            content_list = line.split(\" \")\n",
    "                            #print (\"f\", content_list [3])\n",
    "                            content_list=np.array (content_list,dtype=float) \n",
    "                            data_list.append (content_list)\n",
    "                if (countframe==0) and (\"ITEM: ATOMS\" in content_list ):\n",
    "                        read_n=True\n",
    "\n",
    "    #print (data_list)\n",
    "    data_list=np.array (data_list,dtype=float) \n",
    "\n",
    "    \n",
    "    return (data_list)\n",
    "\n",
    "def save_im (data_list, name , jj, color=True, coll=11, size=25,vmin=0., vmax=1.,marker='h', data_source=None, showw=False):\n",
    "    #fname='./LAMMPS_OUT_FILES/dump_small_mobile.stress'\n",
    "    #data_list =read_result (fname)\n",
    "    size_=size\n",
    "    #print (len(data_list) )\n",
    "    #plt.scatter(x, y, c=z, s=5, cmap=colormap, norm=normalize, marker='*')\n",
    "\n",
    "    stdev_=0\n",
    "    variance_=0\n",
    "    mean_=0\n",
    "    plt.figure(figsize=(10,10))\n",
    "    #print (data_list.shape )\n",
    "    if color== True:    \n",
    "        colormap = plt.cm.jet #or any other colormap\n",
    "        normalize = matplotlib.colors.Normalize(vmin=vmin, vmax=vmax)\n",
    "        if coll>4 and coll<20:\n",
    "            \n",
    "            data_list_data=data_list\n",
    "            if not data_source is None:\n",
    "                data_list_data=data_source\n",
    "            plt.scatter(data_list[:, 1], data_list[:, 2], c=data_list_data[:, coll], \\\n",
    "                        marker=marker, s=size_, cmap=colormap, norm=normalize );\n",
    "            stdev_=statistics.stdev (data_list_data[:, coll])\n",
    "            variance_=statistics.variance (data_list_data[:, coll])\n",
    "            mean_=statistics.mean (data_list_data[:, coll])\n",
    "            #plt.tricontourf(data_list[:, 1], data_list[:, 2],  data_list[:, coll], cmap='jet');\n",
    "        if coll==4:\n",
    "            plt.scatter(data_list[:, 1], data_list[:, 2], c=data_list[:, coll], marker=marker, s=size_, cmap='CMRmap');\n",
    "        \n",
    "             \n",
    "        if coll==20: #x displacement\n",
    "            \n",
    "            plt.scatter(data_list[:, 1], data_list[:, 2], c=data_list[:, 1]-data_source[:, 1], marker=marker, s=size_, cmap=colormap, norm=normalize );\n",
    "        if coll==21: #y displacement\n",
    "            \n",
    "            plt.scatter(data_list[:, 1], data_list[:, 2], c=data_list[:, 2]-data_source[:, 2], marker=marker, s=size_, cmap=colormap, norm=normalize );\n",
    "        if coll==22: #y displacement\n",
    "            \n",
    "            plt.scatter(data_list[:, 1], data_list[:, 2], c=data_list[:, 3]-data_source[:, 3], marker=marker, s=size_, cmap=colormap, norm=normalize );\n",
    "            \n",
    "            #plt.tricontourf(data_list[:, 1], data_list[:, 2],  data_list[:, coll]);\n",
    "    if color== False:    \n",
    "        plt.scatter(data_list[:, 1], data_list[:, 2], c=\"black\" , marker=marker, s=size_, cmap='jet');\n",
    "    \n",
    "    plt.subplots_adjust(left=0., bottom=0., right=1., top=1.)\n",
    "    plt.axis('square')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    #fig = plt.figure()\n",
    "    #plt.figure().subplots_adjust(\n",
    "    #top=0.0,\n",
    "    #bottom=0.0,\n",
    "    #left=0.0,\n",
    "    #right=1.0,\n",
    "    #hspace=0.0,\n",
    "    #wspace=0.0\n",
    "    #)\n",
    "    \n",
    "    #fig.tight_layout()\n",
    "    #jj=10\n",
    "    #plt.set_size_inches(5, 8)\n",
    "    \n",
    "    \n",
    "    final_name= name+\"%5.5d.png\"%jj\n",
    "    \n",
    "    #plt.savefig(name+\"%5.5d.png\"%jj, dpi=100,pad_inches=0, bbox_inches='tight' ) #save as png\n",
    "    temp=\"temp.png\"\n",
    "    plt.savefig(temp, dpi=200,pad_inches=0  ) #save as png\n",
    "    \n",
    "    if showw==True:\n",
    "        plt.show()\n",
    "    #cv2.imwrite('/path/to/destination/image.png',image)\n",
    "    \n",
    "    \n",
    "     \n",
    "    print (\"Open image....\") \n",
    "    # Opens a image in RGB mode\n",
    "    im = Image.open(temp,mode='r')\n",
    "    width, height = im.size\n",
    "    cropp=width*.04\n",
    "    # Setting the points for cropped image\n",
    "    left = cropp\n",
    "    top = cropp\n",
    "    right = width -cropp \n",
    "    bottom = height -cropp\n",
    "\n",
    "    # Cropped image of above dimension\n",
    "    # (It will not change original image)\n",
    "    im1 = im.crop((left, top, right, bottom))\n",
    "    \n",
    "    im1 = im1.resize( (width, height) )\n",
    "    \n",
    "    im1.save(final_name,  format=\"png\")\n",
    "\n",
    "    return final_name, stdev_, variance_, mean_\n",
    "\n",
    "def same_orig_im (forpx,forpy,name, jj ):\n",
    "    \n",
    " \n",
    "    plt.scatter(forpx , forpy  ,marker='s', s=1, c=\"black\" )\n",
    "    #plt.axis('off')\n",
    "                \n",
    "    final_name= name+\"%5.5d.png\"%jj\n",
    "    plt.savefig(final_name, dpi=200,pad_inches=0 ) #save as png\n",
    "    plt.axis('square')\n",
    "    plt.show()\n",
    "    return final_name    \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a51cb3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "        \n",
    "\n",
    "#takes lists earlier generated and writes LAMMPS coor file\n",
    "def gen_LAMMPS_cor_voxel (forpx, forpy,forpz, atomlist, bondlist, pbcx,pbcy,pbcz,\n",
    "                          outname='./data_harmonic.coor'):\n",
    "           \n",
    "        \n",
    "\n",
    "    \n",
    "    bnumber = len(bondlist)-1\n",
    "    header=[]\n",
    "\n",
    "    header.append(('\\n%d atoms \\n'% (len(atomlist)-1) ))\n",
    "    header.append(('%d bonds \\n'% bnumber))\n",
    "    #header.append ('%d angles \\n'% anglenumber )\n",
    "\n",
    "    header.append ('\\n' )\n",
    "\n",
    "    header.append (('%d atom types \\n'% 1 ))\n",
    "    header.append (('%d bond types \\n'% 1 ))\n",
    "    #header.append (('%d angle types \\n'% 1 ) )\n",
    "\n",
    "\n",
    "    header.append ('\\n' )\n",
    "\n",
    "    header.append (f'{-pbcx} {pbcx}    xlo xhi \\n' )\n",
    "    header.append (f'{-pbcy} {pbcy}    ylo yhi \\n' )\n",
    "    header.append (f'{-pbcz} {pbcz}    zlo zhi \\n' )\n",
    "\n",
    "    header.append ('\\n\\n' )\n",
    "\n",
    "    header.append ('Masses \\n\\n')\n",
    "    header.append ('1  1.00 \\n')\n",
    "   \n",
    "    header.append ('\\n' )\n",
    "\n",
    "#1 12.01\n",
    "#2 1.00794\n",
    "\n",
    "    #####################\n",
    "    # write file\n",
    "\n",
    "\n",
    "    file = open(outname,\"w\")\n",
    "\n",
    "    file.writelines(header)\n",
    "    file.writelines(atomlist)\n",
    "    file.writelines(bondlist)\n",
    "    #file.writelines(anglelist)\n",
    "\n",
    "\n",
    "    file.close()\n",
    "    return\n",
    "\n",
    "#this must generate atom lists, bond lists etc. to be written later\n",
    "def gen_LAMMPS_coord_from_voxel (im, r0_lattice_x, r0_lattice_y,r0_lattice_z, \n",
    "                                 ux, uy, uz, attype, precise=True, \n",
    "                                 r_cut=1.1, delete_unbonded=False):\n",
    "\n",
    "    #before: image = number of unit cells\n",
    "    #maxx=im.shape[1]\n",
    "    #maxy=im.shape[0]\n",
    "    \n",
    "    \n",
    "    if precise:\n",
    "        maxx=int (im.shape[0]/r0_lattice_x)\n",
    "        maxy=int (im.shape[1]/r0_lattice_y)\n",
    "        maxz=int (im.shape[2]/r0_lattice_z)\n",
    "    else:\n",
    "        maxx=  im.shape[0] \n",
    "        maxy=  im.shape[1] \n",
    "        maxz=  im.shape[2] \n",
    "    \n",
    "    #spacing of lattice\n",
    "\n",
    "    #UNIT: Angstroms\n",
    "\n",
    "    sizexx=maxx*1\n",
    "    sizeyy=maxy*1\n",
    "    sizeyz=maxz*1\n",
    "    \n",
    "    print (\"-------------------------------------------------------------------------\")\n",
    "    print (\"Image dimensions: \", maxy, maxx, maxz)\n",
    "    print (\"-------------------------------------------------------------------------\")\n",
    "    atomlist=[]\n",
    "    bondlist =[]\n",
    "    anglelist =[]\n",
    "\n",
    "\n",
    "    forp=[]\n",
    "    forpx=[]\n",
    "    forpy=[]\n",
    "    forpz=[]\n",
    "    forptype=[] \n",
    "\n",
    "    ucellsize=len (ux)\n",
    "    anumber = 0    \n",
    "    bnumber = 0\n",
    "    anglenumber =0   \n",
    "    for i in range ( int(maxx)):\n",
    "        if i%100==0:\n",
    "            print (\"Now checking i= \", i)\n",
    "        for j in range (int(maxy)):\n",
    "            for k in range (int(maxz)):\n",
    "                \n",
    "                for kk in range ( ucellsize):\n",
    "\n",
    "                    #print (kk)  \n",
    "                    dx=ux[kk]\n",
    "                    dy=uy[kk]\n",
    "                    dz=uz[kk]\n",
    "\n",
    "                    #atype=1\n",
    "                    #molid=1\n",
    "\n",
    "                    #print (i, j)\n",
    "                    #print (kk, dx, dy)\n",
    "                    xxx=i*r0_lattice_x +dx\n",
    "                    yyy=j*r0_lattice_y +dy\n",
    "                    zzz=k*r0_lattice_z +dz\n",
    "\n",
    "                    #add=False\n",
    "                    if precise:\n",
    "                        atype=get_material_type_voxel  (im , int (xxx), int (yyy), int (zzz)  )\n",
    "                    else:\n",
    "                        atype=get_material_type_voxel  (im , int (i), int (j), int (k)  )\n",
    "                    \n",
    "                    #atype=get_material_type_voxel  (im , int (xxx), int (yyy), int (zzz)  )\n",
    "                    #add=is_material (im , j, i) \n",
    "                    #print (atype)\n",
    "\n",
    "                    if atype>1:     \n",
    "                        #print (\"***\", add)\n",
    "                        anumber=anumber+1\n",
    "                        attype_=attype[kk] # get particular atom type from unit cell - need to change if use multispecies LJ...\n",
    "            #            chh= (\"%d %d %d %f %f %f \\n\") % (anumber, molid, atype, \n",
    "            #                                             xxx,yyy,zzz)\n",
    "                        molid=1\n",
    "                        chh= (\"%d %d %d %f %f %f \\n\") % (anumber, molid, attype_, xxx,yyy,zzz)\n",
    "            \n",
    "                        #chh= (\"%d  %d  %10.4f  %10.4f  %10.4f\\n\") % (anumber,   attype_, \n",
    "                        #                                 xxx,yyy,zzz)\n",
    "                        atomlist.append ( chh)\n",
    "\n",
    "                        forp.append( [xxx,yyy, zzz])\n",
    "                        forpx.append( xxx)\n",
    "                        forpy.append( yyy)\n",
    "                        forpz.append( zzz)\n",
    "                        \n",
    "                        forptype.append(atype)\n",
    "                #if add==False:    # now we are in INTERIOR of channel... the fluid  \n",
    "\n",
    "                \n",
    "                \n",
    "    print (\"Number atoms added: \", len(forpx) )        \n",
    "    \n",
    "    \n",
    "    #now generate bonds\n",
    "    \n",
    "    #first, translate list to np array for fast comp\n",
    "    forp_np = np.array(forp)\n",
    "\n",
    "    print (\"Shape coordinate list: \", forp_np.shape)\n",
    "    \n",
    "    ######################### Generate bond list....\n",
    "    #euclidean_distance = np.linalg.norm(np.array(features)-np.array(predict))\n",
    "    #        print(euclidean_distance)\n",
    "    bonded=[]\n",
    "        \n",
    "    bnumber = 0\n",
    "    for i in range ( forp_np.shape[0]):\n",
    "        \n",
    "        x0=forp_np[i, 0]\n",
    "        y0=forp_np[i, 1]\n",
    "        z0=forp_np[i, 2]\n",
    "        \n",
    "        if i%1000==0:\n",
    "            print (\"Progress: \", i)\n",
    "        \n",
    "        j=i+1\n",
    "        while j<  forp_np.shape[0]:\n",
    "    \n",
    "            x1=forp_np[j, 0]\n",
    "            y1=forp_np[j, 1]\n",
    "            z1=forp_np[j, 2]\n",
    "            #r=10\n",
    "            r= np.sqrt((x1-x0)**2 + (y1-y0)**2 + (z1-z0)**2)\n",
    "            \n",
    "            #print (r)\n",
    "            \n",
    "            if r < r_cut and j>i: #only add bonds ONCE\n",
    "                #print (\"bond found: \", i+1, j+1, r)\n",
    "                \n",
    "                btype=1\n",
    "                bnumber=bnumber+1 \n",
    "\n",
    "                chh= (\"%d  %d    %d %d  \\n\") % (bnumber, btype,  i+1, j+1 )\n",
    "                bondlist.append ( chh)  \n",
    "                \n",
    "                bonded.append(i)\n",
    "                bonded.append(j)\n",
    "                \n",
    "            j=j+1\n",
    "            \n",
    "    if delete_unbonded:        \n",
    "        #remove atoms not bonded\n",
    "        dellist=[]\n",
    "        for i in range ( forp_np.shape[0]):\n",
    "            if i not in bonded:\n",
    "\n",
    "                dellist.append(i)\n",
    "\n",
    "\n",
    "\n",
    "        dellist=list(OrderedDict((element, None) for element in dellist))\n",
    "\n",
    "        print (\"to be deleted.... \", dellist)\n",
    "\n",
    "        for ele in sorted(dellist, reverse = True):\n",
    "            \n",
    "            '''\n",
    "            del atomlist[ele]\n",
    "            del forp[ele]\n",
    "            del forpx[ele]\n",
    "            del forpy[ele]\n",
    "            del forpz[ele]\n",
    "            del forptype[ele]\n",
    "            '''\n",
    "            print(\"delete unbonded particles doesnt work yet... need to renumber particles\")\n",
    "            \n",
    "            #chh[ele]= (\"%d %d %d %f %f %f \\n\") % (ele, molid, 2, xxx,yyy,zzz)\n",
    "             \n",
    "            \n",
    "    atomlist.insert (0, 'Atoms \\n\\n')\n",
    "          \n",
    "    bondlist.insert (0,'\\nBonds \\n\\n')\n",
    "    \n",
    "    \n",
    "    return atomlist, bondlist, forp, forpx, forpy, forpz, forptype\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc14dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dest = './Voxel_runs/'\n",
    "os.makedirs(dest , exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b22768",
   "metadata": {},
   "outputs": [],
   "source": [
    "!set OMP_NUM_THREADS=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761117fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "v=load_voxel ('np_vox_0000_0000.npy')\n",
    "\n",
    "im_resx = v.shape[0]\n",
    "im_resy = v.shape[0]\n",
    "im_resz = v.shape[0]\n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762f3345",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_string (data,rp1, rp1_n):\n",
    "    data=data.replace(rp1, rp1_n)\n",
    "    return data\n",
    " \n",
    "def set_sim_parameters (fname=\"in_python_FCC_harmonic_reference_pull.txt\", \n",
    "                        fnameout=\"in_python_FCC_voxel_harmonic_pull_PROCESSED.txt\",\n",
    "                       k_spring=10., r0=5.):\n",
    "    text_file = open(fname, \"r\")\n",
    "    #read whole file to a string\n",
    "    data = text_file.read()\n",
    "    #close file\n",
    "    text_file.close()\n",
    "    #print(data)\n",
    "    \n",
    "    print (\"Set FF parameters...\", k_spring, r0)\n",
    "\n",
    "    #DONT NEED FOR PBCs... just leave here anyway\n",
    "    \n",
    "\n",
    "    b_1='bond_coeff\t1 100 1.'\n",
    "    b_1_n=f\"bond_coeff    1 {k_spring:.5f} {r0:.5f}\"\n",
    "    \n",
    "    \n",
    "    data=replace_string (data,b_1, b_1_n)\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    # LJ potential \n",
    "    b_1='#pair_style\tlj/cut 0.8'\n",
    "    b_1_n=f\"pair_style\tlj/cut {r0:.5f}\" #cutoff at r_0 so only have repulsive part\n",
    "    data=replace_string (data,b_1, b_1_n)\n",
    "    \n",
    "    b_1='#pair_coeff\t* * 0. 1.'\n",
    "    sigma = r0/ (2**(1/6.))\n",
    "    eps = k_spring/5\n",
    "    b_1_n=f\"pair_coeff * * {eps} {sigma}\"  #sigma r0= 2**(1/6.) * sigma  --- sigma = r0/ (2**(1/6.))\n",
    "    data=replace_string (data,b_1, b_1_n)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #k ... cutoff\n",
    "    #b_1='pair_coeff * * 0.2 2.0'\n",
    "    #b_1_n=f\"pair_coeff * * {k_spring:.5f} {r0:.5f}\"\n",
    "    \n",
    "\n",
    "    #data=replace_string (data,b_1, b_1_n)\n",
    "    \n",
    "\n",
    "    #print (data)\n",
    "    text_file = open(fnameout, \"w\")\n",
    "    #read whole file to a string\n",
    "    text_file.write(data)\n",
    "    #close file\n",
    "    text_file.close()\n",
    "    \n",
    "\n",
    "def setup_FCC_harmonic (r0=4.5 ):\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #r0_lattice=.93*2\n",
    "\n",
    "    #r0_lattice = 2**0.5 * r0\n",
    "    r0_lattice = 2**0.5 * r0\n",
    "\n",
    "    #print (r0, r0_lattice)\n",
    "    #harmonic\n",
    "    r0_lattice_x=r0_lattice\n",
    "    r0_lattice_y=r0_lattice\n",
    "    r0_lattice_z=r0_lattice\n",
    "\n",
    "\n",
    "\n",
    "    ux = [0,             0  ,                  0.5*r0_lattice,           0.5*r0_lattice]\n",
    "    uy = [0.,            0.5*r0_lattice,       0.  ,                    0.5*r0_lattice ] \n",
    "    uz = [0,             0.5*r0_lattice,       0.5*r0_lattice,            0] \n",
    "\n",
    "    #coordinates\n",
    "    #0,0,0; 0,1/2,1/2; 1/2,0,1/2; and 1/2,1/2,0\n",
    "\n",
    "\n",
    "    r0_lattice_x=r0_lattice\n",
    "    r0_lattice_y=r0_lattice\n",
    "    r0_lattice_z=r0_lattice\n",
    "    ucellsize = len (ux)\n",
    "\n",
    "    attype = [1,1,1,1 ]\n",
    "    #print (\"Unit cell dimension in x,y: \", r0_lattice_x, r0_lattice_y, r0_lattice_z)\n",
    "\n",
    "    return ux, uy, uz, r0_lattice_x, r0_lattice_y, r0_lattice_z, ucellsize, attype\n",
    "\n",
    "\n",
    "    #LJ\n",
    "    #hexagonal\n",
    "    #r0_lattice_x=r0_lattice*2\n",
    "    #r0_lattice_y=r0_lattice * sqrt(3. )\n",
    "    #ucellsize=4\n",
    "    #ux = [0, r0_lattice/2,r0_lattice, r0_lattice*3/2]\n",
    "    #uy = [0, r0_lattice*sqrt(3)/2.,0, r0_lattice*sqrt(3)/2.   ]\n",
    "\n",
    "    #graphene\n",
    "    '''\n",
    "    sqrt3= sqrt(3)\n",
    "    bondl=1.42\n",
    "    r0_lattice_x=sqrt3*bondl * 2 ## two copies in x\n",
    "    r0_lattice_y=3*bondl\n",
    "\n",
    "    ucellsize=8\n",
    "    ux = [0,  0.5*sqrt3*bondl, 0.5*sqrt3*bondl, 0.0, \\\n",
    "          0+r0_lattice_x/2.,  0.5*sqrt3*bondl+r0_lattice_x/2., 0.5*sqrt3*bondl+r0_lattice_x/2., 0.0+r0_lattice_x/2.]\n",
    "    uy = [0.5*bondl, bondl ,2*bondl, 2.5*bondl,.5*bondl, bondl ,2*bondl, 2.5*bondl   ]\n",
    "\n",
    "    attype = [1,1,1,1, 1,1,1,1]\n",
    "    print (\"Unit cell dimension in x,y: \", r0_lattice_x, r0_lattice_y)\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9917c510",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def set_pulling (filename=\"in_python_FCC_voxel_harmonic_pull_PROCESSED.txt\", low_z=20, high_z=60,  deltaz=10,\n",
    "                 vx=0.0, vy=0.0, vz=0.1, pullsteps=20000, timestep = 0.075, LAMMPS_OUT = './LAMMPS_OUT_FILES/'):\n",
    "\n",
    "    text_file = open(filename, \"r\")\n",
    "    #read whole file to a string\n",
    "    data = text_file.read()\n",
    "    #close file\n",
    "    text_file.close()\n",
    "    #print(data)\n",
    "\n",
    "    #region....xlo xhi ylo yhi zlo zhi\n",
    "    #print (\"Data provided: \", pullsteps, vx,vz,vz, low_z, high_z, deltaz)\n",
    "    \n",
    "    #vx=0.0\n",
    "    #vy=0.0\n",
    "    #vz=0.1\n",
    "    \n",
    "    #ramp command\n",
    "    \n",
    "    #value = x + (y-x) * (timestep-startstep) / (stopstep-startstep)\n",
    "    \n",
    "    data=replace_string(data,rp1= \"timestep 0.075\",  \n",
    "                   rp1_n=f\"timestep     {timestep}\")\n",
    "   \n",
    "    #DONT NEED FOR PBCs... just leave here anyway\n",
    "    data=replace_string(data,rp1= \"#region\t        1 block INF INF INF 10 INF INF\",  \n",
    "                   rp1_n=f\"region\t        1 block INF INF INF INF INF  {low_z+deltaz} \")\n",
    "    \n",
    "    data=replace_string(data,rp1= \"#group\t\tlower region 1\",  \n",
    "                   rp1_n=f\"group\t\tlower region 1\")\n",
    "    \n",
    "    data=replace_string(data,rp1=\"#region\t\t2 block INF INF 118 INF INF INF\",\n",
    "                   rp1_n=f\"region\t        2 block INF INF INF INF {high_z-deltaz} INF\")\n",
    "                        \n",
    "    data=replace_string(data,rp1= \"#group\t\tupper region 2\",  \n",
    "                   rp1_n=f\"group\t\tupper region 2\")\n",
    "    \n",
    "    data=replace_string(data,rp1= \"#group\t\tboundary union lower upper\",  \n",
    "                   rp1_n=f\"group\t\tboundary union lower upper\")\n",
    "    \n",
    "    data=replace_string(data,rp1= \"#group\t\tmobile subtract all boundary\",  \n",
    "                   rp1_n=f\"group\t\tmobile subtract all boundary\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    data=replace_string(data,rp1= \"#velocity\tupper set 0.0 0.3 0.0\",  \n",
    "                   rp1_n=f\"velocity\tupper set {vx} {vy} {vz}\")\n",
    "   \n",
    "    data=replace_string(data,rp1= \"#velocity\tlower set 0.0 0.3 0.0\",  \n",
    "                   rp1_n=f\"velocity\tlower set {-vx} {-vy} {-vz}\")\n",
    "    \n",
    "    maxdisplacement = pullsteps*deltaz*timestep # total displacements after pulling steps...\n",
    "    \n",
    "    data=replace_string(data,rp1= \"#run\t\t20000\",  \n",
    "rp1_n=f'variable \t disp equal \\\"ramp(0, {maxdisplacement})\\\" \\n\\\n",
    "variable \t ssxx equal \\\"-pxx\\\" \\n\\\n",
    "variable \t ssyy equal \\\"-pyy\\\" \\n\\\n",
    "variable \t sszz equal \\\"-pzz\\\"\\n\\\n",
    "variable \t ssxy equal \\\"-pxy\\\" \\n\\\n",
    "variable \t ssxz equal \\\"-pxz\\\" \\n\\\n",
    "variable \t ssyz equal \\\"-pyz\\\" \\n\\\n",
    "\\n\\n\\\n",
    "fix          def1 mobile print 1000 \\\"${{disp}} ${{ssxx}} ${{ssyy}} ${{sszz}} ${{ssxy}} ${{ssxz}} ${{ssyz}} \\\" file {LAMMPS_OUT}/sscurve.dat screen no \\n\\\n",
    "\\n\\n\\\n",
    "run\t\t{pullsteps}  \\n\\n')\n",
    "\n",
    "#run\t\t{pullsteps} start 0 stop {pullsteps}\\n\\n')\n",
    "\n",
    "    data=replace_string(data,rp1= \"#fix\t\t2 boundary setforce 0. 0. 0.\",  \n",
    "                   rp1_n=f\"fix\t\t200 boundary setforce 0. 0. 0.\")\n",
    "    #data=replace_string(data,rp1= \"#fix\t\t2 boundary setforce 0. 0. 0.\",  \n",
    "    #               rp1_n=f\"fix\t\t200 boundary setforce NULL NULL 0.\")\n",
    "   \n",
    "    \n",
    "    \n",
    "   \n",
    "    print (\"####################################################################\")\n",
    "    print (\"## PULLING ADDED...\")\n",
    "    #print (data)\n",
    "    print (\"####################################################################\")\n",
    "    text_file = open(filename, \"w\")\n",
    "    #read whole file to a string\n",
    "    text_file.write(data)\n",
    "    #close file\n",
    "    text_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05cea66a",
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "def append_enmin ( fname=\"in_python_FCC_voxel_harmonic_pull_PROCESSED.txt\", steps=1000, \n",
    "                  maxeval=10000, LAMMPS_OUT='./LAMMPS_OUT_FILES/'):\n",
    "    text_file = open(fname, \"r\")\n",
    "    #read whole file to a string\n",
    "    data = text_file.read()\n",
    "    #close file\n",
    "    text_file.close()\n",
    "    #print(data)\n",
    "    \n",
    "    vx=0\n",
    "    vy=0\n",
    "    vz=0\n",
    "    \n",
    "    data=replace_string(data,rp1= \"stop_simulation\",  \n",
    "                   rp1_n=f\"velocity\tlower set {-vx} {-vy} {-vz}\\nvelocity\tupper set {-vx} {-vy} {-vz}\\n \\nstop_simulation\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    data=replace_string(data,rp1= \"stop_simulation\",  \n",
    "                   rp1_n=f\"min_style cg\\nminimize        1e-8 1e-8 {steps} {maxeval}\\n\\nstop_simulation\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    str_=f'###################FINAL STRESS FIELD#####################################\\n\\\n",
    "dump stressfinal all custom 1 ./{LAMMPS_OUT}/dump_final.stress id x y z v_sxx v_syy v_szz v_sxy v_sxz v_syz v_mises\\n\\\n",
    "####################################################################\\n\\nrun 0\\n\\nstop_simulation'\n",
    "\n",
    "    data=replace_string(data,rp1= \"stop_simulation\",  \n",
    "                   rp1_n=str_)\n",
    "\n",
    "    str_='###################FINAL STRESS FIELD ONLY MOBILE#####################################\\n\\\n",
    "dump stressfinal_mobile mobile custom 1 ./LAMMPS_OUT_FILES/dump_final_mobile.stress id x y z v_sxx v_syy v_szz v_sxy v_sxz v_syz v_mises\\n\\\n",
    "####################################################################\\n\\nrun 0\\n\\nstop_simulation'\n",
    "\n",
    "    data=replace_string(data,rp1= \"stop_simulation\",  \n",
    "                   rp1_n=str_)\n",
    "\n",
    "    \n",
    "\n",
    "    #data.append (f\"min_style cg\\n minimize        1e-8 1e-8 {steps} {maxeval}\\n\\nstop\")    \n",
    "    #print (data)\n",
    "    text_file = open(fname, \"w\")\n",
    "    #read whole file to a string\n",
    "    text_file.write(data)\n",
    "    #close file\n",
    "    text_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8ab7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_output_directory ( fname=\"in_python_FCC_voxel_harmonic_pull_PROCESSED.txt\", \n",
    "                          ORIGINAL='./LAMMPS_OUT_FILES/', LAMMPS_OUT = './LAMMPS_OUT_FILES_NEW/', coordname='./data_harmonic_hres.coor'):\n",
    "    text_file = open(fname, \"r\")\n",
    "    #read whole file to a string\n",
    "    data = text_file.read()\n",
    "    #close file\n",
    "    text_file.close()\n",
    "    #print(data)\n",
    "    \n",
    "    vx=0\n",
    "    vy=0\n",
    "    vz=0\n",
    "    \n",
    "    data=replace_string(data,rp1= ORIGINAL,  \n",
    "                   rp1_n=LAMMPS_OUT)\n",
    "    \n",
    "    data=replace_string(data,rp1= \"./data_harmonic.coor\",  \n",
    "                   rp1_n=coordname)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #data.append (f\"min_style cg\\n minimize        1e-8 1e-8 {steps} {maxeval}\\n\\nstop\")    \n",
    "    #print (data)\n",
    "    text_file = open(fname, \"w\")\n",
    "    #read whole file to a string\n",
    "    text_file.write(data)\n",
    "    #close file\n",
    "    text_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f94e9215",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_plot_stress (fname='./LAMMPS_OUT_FILES/sscurve.dat', miniter= 0, \n",
    "                         maxiter=100 , modulus_dir=3, i=0, show_on=True, LAMMPS_OUT='./' ):\n",
    "    stressdata=pd.read_csv(fname, delimiter='\\s+',skiprows=1)\n",
    "    print (\"Stress data shape: \", stressdata.shape)\n",
    "    #print (stressdata)\n",
    "    #${disp} ${ssxx} ${ssyy} ${sszz} ${ssxy} ${ssxz} ${ssyz}\n",
    "    if show_on:\n",
    "\n",
    "        plt.plot (stressdata.iloc[:,0], stressdata.iloc[:,1], label='$\\sigma_{xx}$')\n",
    "        plt.plot (stressdata.iloc[:,0], stressdata.iloc[:,2], label='$\\sigma_{yy}$')\n",
    "        plt.plot (stressdata.iloc[:,0], stressdata.iloc[:,3], label='$\\sigma_{zz}$')\n",
    "        plt.plot (stressdata.iloc[:,0], stressdata.iloc[:,4], label='$\\sigma_{xy}$')\n",
    "        plt.plot (stressdata.iloc[:,0], stressdata.iloc[:,5], label='$\\sigma_{xz}$')\n",
    "        plt.plot (stressdata.iloc[:,0], stressdata.iloc[:,6], label='$\\sigma_{yz}$')\n",
    "\n",
    "        plt.legend()\n",
    "\n",
    "        outname =   f'{LAMMPS_OUT}/stressplot_{i}.jpg'#f\"./HIST_epoch_high-{epoch+start_h}-option-{epoch}.jpg\"\n",
    "        plt.savefig(outname, dpi=300)\n",
    "        plt.show()\n",
    "\n",
    "    #calculate modulus\n",
    "    modulus= (stressdata.iloc[maxiter,modulus_dir]-stressdata.iloc[miniter,modulus_dir])/(maxiter-miniter)\n",
    "    print (f\"Modulus in {modulus_dir} direction = {modulus} - tangent at {miniter}..{maxiter}\")\n",
    "    \n",
    "    max_stress= max(stressdata.iloc[:,modulus_dir])\n",
    "    print (f\"Max stress in {modulus_dir} direction = {max_stress}\")\n",
    "           \n",
    "    return modulus, max_stress\n",
    "           \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14fc6aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_stress_field(fname='./LAMMPS_OUT_FILES/dump_final.stress' , i=0, \n",
    "                         ilocal=10, show_on=True, LAMMPS_OUT='./'  ):\n",
    "    #  id x y z v_sxx v_syy v_szz v_sxy v_sxz v_syz v_mises\n",
    "    #  0  1 2  3  4     5     6     7     8     9     10\n",
    "    stressfield=pd.read_csv(fname, delimiter='\\s+',skiprows=9)#skip first 9 rows... header...\n",
    "    \n",
    "    if show_on:\n",
    "\n",
    "        #print (stressfield)\n",
    "        fig_handle = sns.distplot(stressfield.iloc[:,ilocal],bins=30,kde=False, \n",
    "                                  rug=False,norm_hist=False,axlabel='Stress' )\n",
    "        fig = fig_handle.get_figure()\n",
    "        fig.savefig(f'{LAMMPS_OUT}/stress_dist_iteration-{i}_stresscomponent-{ilocal}.png',dpi=300)\n",
    "        plt.show()\n",
    "    \n",
    "    s_mean = np.mean (stressfield.iloc[:,ilocal])\n",
    "    s_std = np.std (stressfield.iloc[:,ilocal])\n",
    "    s_var = np.var (stressfield.iloc[:,ilocal])\n",
    "    \n",
    "    print (f\"Stress mean={s_mean}, stress stanard dev={s_std}, stress variance={s_var}\")\n",
    "    \n",
    "    return s_mean, s_std, s_var, stressfield\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c3e087",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#s_mean, s_std, s_var, stressfield=analyze_stress_field(fname='./LAMMPS_OUT_FILES/dump_final.stress' , i=0 , ilocal=10) #ilocal = entry of stress tensor..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9226b634",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_data (  modulus_list , max_stress_list , smean_list ,  \n",
    "                             stddev_list , svar_list , voxellist, pointcloudlist,  STLfilename, loc,\n",
    "               fname=\"output_results.csv\"):\n",
    "    \n",
    "    print (\"Write CSV....\")\n",
    "    file = open(fname, \"w+\", newline='')\n",
    "    writer = csv.writer(file)\n",
    "    header = ['modulus', 'max_stress','stress_mean', 's_stddev', 's_var', 'voxel_file', 'pointcloud_file', \n",
    "              'STL_file', 'STL_file_loc']\n",
    "    writer.writerow(header)\n",
    "    print (\"Write data...\")\n",
    "    for w in range(len (modulus_list)): #iterate through  \n",
    "\n",
    "          writer.writerow  ([modulus_list [w], max_stress_list [w], smean_list [w],  \n",
    "                             stddev_list [w], svar_list [w], voxellist[w], pointcloudlist [w],  STLfilename[w], loc ])\n",
    "\n",
    "    file.close()\n",
    "    \n",
    "    #return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209fe93c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import time\n",
    " \n",
    "    \n",
    "def run_sims (size_voxel_set=64,#note = 64 in all directions, so actual size is double\n",
    "             threshold=0.8,\n",
    "             sizevoxel =1.,\n",
    "             k_spring= 5.,\n",
    "             r0=3.5,\n",
    "             use_omp = False ,\n",
    "              loc='./STL_collection/',\n",
    "              STL_fnames=None,\n",
    "              startjj=0,\n",
    "             smean_list=[],\n",
    "            svar_list=[],\n",
    "            stddev_list=[],\n",
    "            max_stress_list=[],\n",
    "            modulus_list=[],\n",
    "            voxellist=[],\n",
    "            pointcloudlist=[],\n",
    "              STLfilename=[],\n",
    "               csv_fname=\"output_results_averaged.csv\",\n",
    "             LAMMPS_OUT='./LAMMPS_OUT_FILES/',\n",
    "              pullsteps=500000,\n",
    "              vspeed=(0, 0, 0.005),\n",
    "              coord_name='./data_harmonic_highres.coor',\n",
    "             show_on=False ,\n",
    "             reorient=False,\n",
    "             scaled=False,\n",
    "             fnameout=\"in_python_FCC_voxel_harmonic_pull_PROCESSED_highres.txt\"):\n",
    "\n",
    "    os.makedirs(LAMMPS_OUT, exist_ok=True)\n",
    "\n",
    "    if STL_fnames==None:\n",
    "        print (\"ERROR - no STL files provided....\")\n",
    "        return \n",
    "    \n",
    "    #pbcx=r0_lattice_x*im_resx#*r0_lattice_x\n",
    "    #pbcy=r0_lattice_y*im_resy#*r0_lattice_y\n",
    "    #pbcz=r0_lattice_z*im_resz\n",
    "    pbcx=size_voxel_set *2#*r0_lattice_x\n",
    "    pbcy=size_voxel_set *2#*r0_lattice_y\n",
    "    pbcz=size_voxel_set *2\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #safefac=1.35\n",
    "    #threshold =-0.5\n",
    "    #threshold =0.05\n",
    "\n",
    "    #print (\"min/max in image dims\", xmin, xmax, ymin, ymax )\n",
    "\n",
    "    #name_list_CSV=[]\n",
    "\n",
    "    #STL_fnames = ['gyroid_test_2.obj']\n",
    "    #STL_fnames = ['voxel_0_tester_0_06_11_05_45.stl']\n",
    "    #STL_fnames = ['voxel_0_tester_0_06_11_05_45.stl','voxel_0_tester_0_06_11_05_45.stl']\n",
    "\n",
    "    #STL_fnames = ['voxel_0_tester_0_06_11_05_45.stl']\n",
    "\n",
    "    #print (STL_fnames)\n",
    "\n",
    "    num_sims = len (STL_fnames)\n",
    "\n",
    "    \n",
    "    \n",
    "    for jj in range (0, num_sims):\n",
    "        print (\"CASE SIMULATION: \", jj , \" out of: \", num_sims)\n",
    "        \n",
    "        \n",
    "\n",
    "        ux, uy, uz, r0_lattice_x, r0_lattice_y, r0_lattice_z, ucellsize, attype= setup_FCC_harmonic (r0=r0 )\n",
    "\n",
    "      \n",
    "        print (\"Considering: \", STL_fnames[jj])\n",
    "\n",
    "        im, _, _, STLfilename_=show_stl2point (loc=loc, fname=STL_fnames[jj], \n",
    "                                 size=size_voxel_set, sizevoxel =sizevoxel , \n",
    "                                 reorient=reorient, threshold=threshold, scaled=scaled, show_on=show_on  )\n",
    "\n",
    "        STLfilename.append(STLfilename_)\n",
    "     \n",
    "\n",
    "        atomlist, bondlist, forp, forpx, forpy, forpz, forptype=gen_LAMMPS_coord_from_voxel (im,\n",
    "                                                                                  r0_lattice_z, \n",
    "                                                                                              delete_unbonded=True)\n",
    "\n",
    "        if show_on:\n",
    "            print (\"###################################################################################\")\n",
    "            print (\"PLOT ACTUAL ATOM GEOMETRY....\")\n",
    "            print (\"###################################################################################\")\n",
    "            print(\"Number of atoms generated: \", len(atomlist))\n",
    "            #print (anumber)\n",
    "            print (\"max x: \", max (forpx), \"max y: \", max(forpy), \"max z: \", max(forpz))\n",
    "            print (\"min x: \", min (forpx), \"min y: \", min(forpy), \"min z: \", min(forpz))\n",
    "\n",
    "            print ('extensions x, y, z', max (forpx)-min (forpx),  max (forpy)-min (forpy), max (forpz)-min (forpz)) \n",
    "\n",
    "        if show_on:\n",
    "            plt.scatter (forpx, forpz, c='red', marker='s', s=2)\n",
    "            plt.axis('square')\n",
    "            plt.show()\n",
    "\n",
    "            plt.scatter (forpy, forpz, c='red', marker='s', s=2)\n",
    "            plt.axis('square')\n",
    "            plt.show()\n",
    "\n",
    "       \n",
    "        gen_LAMMPS_cor_voxel (forpx, forpy, forpz, atomlist, bondlist, pbcx, pbcy, pbcz, \n",
    "                              outname=coord_name)\n",
    "\n",
    "        \n",
    "        if show_on:\n",
    "\n",
    "            gs = gridspec.GridSpec(1, 1)\n",
    "            gs.update(wspace=0.05, hspace=0.05)\n",
    "\n",
    "            ax = plt.subplot(gs[0], projection='3d')\n",
    "            ax.scatter(forpx, forpy, forpz, zdir='z', c='red', marker='s', s=2)\n",
    "            ax.set_xticklabels([])\n",
    "            ax.set_yticklabels([])\n",
    "\n",
    "            ax.set_xlim((0,pbcx))\n",
    "            ax.set_ylim((0,pbcy))\n",
    "            ax.set_zlim((0,pbcz))\n",
    "\n",
    "\n",
    "            plt.show ()\n",
    "\n",
    "        set_sim_parameters (fname=\"in_python_FCC_harmonic_reference_pull.txt\", \n",
    "                            fnameout=fnameout,\n",
    "                           k_spring=k_spring, r0=r0)\n",
    "        timestep = 0.075\n",
    "        #set_pulling (filename=\"in_python_FCC_voxel_harmonic_pull_PROCESSED.txt\", \n",
    "        #             low_z= min(forpz), high_z= max(forpz),  deltaz=5.,\n",
    "        #             vx=0.0, vy=0.0, vz=0.001, pullsteps=300000,  timestep = timestep) \n",
    "        \n",
    "        if show_on:\n",
    "            print (min(forpz),   max(forpz),  5.)\n",
    "            #vspeed=(vx=0, vy=0, vz=0.005),\n",
    "        set_pulling (filename=fnameout, \n",
    "                     low_z= min(forpz), high_z= max(forpz),  deltaz=5.,\n",
    "                     vx=vspeed[0], vy=vspeed[1], vz=vspeed[2], pullsteps=pullsteps,  timestep = timestep,\n",
    "                     LAMMPS_OUT = LAMMPS_OUT) \n",
    "\n",
    "        append_enmin ( fname=fnameout, steps=1000, maxeval=10000, LAMMPS_OUT=LAMMPS_OUT)\n",
    "        ###############\n",
    "        #RUN LAMMPS\n",
    "        #_3 is with higher strain\n",
    "        \n",
    "        \n",
    "        fix_output_directory ( fname=fnameout, \n",
    "                          ORIGINAL='./LAMMPS_OUT_FILES/', LAMMPS_OUT = LAMMPS_OUT,\n",
    "                             coordname=coord_name)\n",
    "        \n",
    "        print (\"RUN LAMMPS...\")\n",
    "        \n",
    "        try:\n",
    "\n",
    "    \n",
    "\n",
    "            start = time.time()\n",
    "\n",
    "            if use_omp==False:\n",
    "            #!lmp.exe -sf omp -pk omp 4 -in ./in_python_FCC_voxel_harmonic_PROCESSED.txt\n",
    "                print ('NO OMP')\n",
    "                !lmp.exe  -screen none -in $fnameout \n",
    "\n",
    "            if use_omp:\n",
    "                print ('OMP')\n",
    "                !lmp.exe  -screen none -sf omp -pk omp 4 -in $fnameout \n",
    "                \n",
    "                \n",
    "                \n",
    "            end = time.time()\n",
    "            print (\"###################################################################################\")\n",
    "            print (f\"LAMMPS took {(end-start)/60.} minutes....\")\n",
    "            print (\"###################################################################################\")\n",
    "\n",
    "            ############ ANALYZE DATA\n",
    "            print (\"stress analysis....\")\n",
    "            modulus, max_stress=analyze_plot_stress (fname=f'{LAMMPS_OUT}/sscurve.dat', \n",
    "                                                     miniter= 0, maxiter=10 , modulus_dir=3, i=jj+startjj ,\n",
    "                                                    show_on=show_on, \n",
    "                                                     LAMMPS_OUT=LAMMPS_OUT)\n",
    "    \n",
    "            print (\"stress stat analysis....\")\n",
    "            s_mean, s_std, s_var, stressfield=analyze_stress_field(fname=f'{LAMMPS_OUT}/dump_final_mobile.stress' , \n",
    "                                                                   i=jj+startjj , ilocal=10,\n",
    "                                                                   show_on=show_on,\n",
    "                                                                  LAMMPS_OUT=LAMMPS_OUT) #ilocal = entry of stress tensor...\n",
    "\n",
    "            if show_on:\n",
    "                print (\"Copy....\")\n",
    "\n",
    "           \n",
    "            \n",
    "            \n",
    "            #print (\"-\")\n",
    "            shutil.copy(f'{LAMMPS_OUT}/dump_final.stress', f'{LAMMPS_OUT}/dump_final_{jj+startjj}.stress')\n",
    "            os.remove(f'{LAMMPS_OUT}/dump_final.stress')\n",
    "            \n",
    "\n",
    "            #print (\"-\")\n",
    "            shutil.copy(f'{LAMMPS_OUT}/dump_final_mobile.stress', f'{LAMMPS_OUT}/dump_final_mobile_{jj+startjj}.stress')\n",
    "            os.remove(f'{LAMMPS_OUT}/dump_final_mobile.stress')\n",
    "\n",
    "            #print (\"-\")\n",
    "            shutil.copy(f'{LAMMPS_OUT}/sscurve.dat', f'{LAMMPS_OUT}/sscurve_{jj+startjj}.dat')\n",
    "            os.remove (f'{LAMMPS_OUT}/sscurve.dat')\n",
    "\n",
    "            #print (\"-\")\n",
    "            shutil.copy(f'{LAMMPS_OUT}/dump_small_mobile.stress', f'{LAMMPS_OUT}/dump_small_mobile_{jj+startjj}.stress')\n",
    "            os.remove(f'{LAMMPS_OUT}/dump_small_mobile.stress')\n",
    "\n",
    "            #print (\"-\")\n",
    "            shutil.copy(f'{LAMMPS_OUT}/dump_small_all.stress', f'{LAMMPS_OUT}/dump_small_all_{jj+startjj}.stress')\n",
    "            os.remove(f'{LAMMPS_OUT}/dump_small_all.stress')\n",
    "\n",
    "            #print (\"-\")\n",
    "            shutil.copy(f'{LAMMPS_OUT}/dump_initial.geom', f'{LAMMPS_OUT}/dump_initial_{jj+startjj}.geom')\n",
    "            os.remove(f'{LAMMPS_OUT}/dump_initial.geom')            \n",
    "            \n",
    "            \n",
    "            \n",
    "\n",
    "            ##################### WRITE VOXEL AND POINTCLOUD DATA \n",
    "            f=f'{LAMMPS_OUT}/'+f'np_vox_{jj+startjj}'\n",
    "            #print (\"save \", f)\n",
    "            #f=outfolder+f'{exc_name}'\n",
    "            np.save(f, im)\n",
    "            voxellist.append(f+'.npy')\n",
    "            if show_on:\n",
    "                print (\"Done copy...\")\n",
    "\n",
    "\n",
    "            f=f'{LAMMPS_OUT}/'+f'np_pointcloud_{jj+startjj}'\n",
    "            if show_on:\n",
    "                print (\"save \", f)\n",
    "            #f=outfolder+f'{exc_name}'\n",
    "            np.save(f, np.array(forp))\n",
    "            pointcloudlist.append(f+'.npy')\n",
    "\n",
    "            smean_list.append(s_mean)\n",
    "            stddev_list.append(s_std)\n",
    "            svar_list.append(s_var)\n",
    "            modulus_list.append(modulus)\n",
    "            \n",
    "            if show_on:\n",
    "                print (\"max stress: \", max_stress)\n",
    "            max_stress_list.append (max_stress)\n",
    "\n",
    "\n",
    "            if show_on:\n",
    "                print (\"CSV file...\")\n",
    "\n",
    "            write_data (modulus_list= modulus_list, max_stress_list =max_stress_list, smean_list =smean_list,  \n",
    "                             stddev_list =stddev_list, svar_list = svar_list , voxellist = voxellist, \n",
    "                        pointcloudlist =pointcloudlist,  STLfilename=STLfilename,loc=loc,\n",
    "                       fname=csv_fname ) # write every step just to make sure....\n",
    "            if show_on:\n",
    "                print (\"Done...\")\n",
    "\n",
    "        except:\n",
    "            print (\"Error occurred for jj=\", jj)\n",
    "\n",
    "    return smean_list,svar_list,stddev_list,max_stress_list,modulus_list,voxellist,pointcloudlist,STLfilename\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a863a71",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "im, _, _,_=show_stl2point (loc='./STL_objects/', fname='gyroid_test.obj', size=64, sizevoxel =.01 , \n",
    "                         reorient=False, threshold=0.8,scaled=True,  )\n",
    "\n",
    "_,_,_,_=show_stl2point (loc='./', fname='voxel_0_tester_0_06_11_05_45.stl', size=64, sizevoxel =1/64. , \n",
    "                reorient=True, threshold=0.8, scaled=True  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb0da42",
   "metadata": {},
   "outputs": [],
   "source": [
    "STL_fnames=[]\n",
    "\n",
    "for i in range (9000,10000):\n",
    "         STL_fnames.append (f'_voxel_0_tester_{i}.stl')\n",
    "smean_list=[]\n",
    "svar_list=[]\n",
    "stddev_list=[]\n",
    "max_stress_list=[]\n",
    "modulus_list=[]\n",
    "voxellist=[]\n",
    "pointcloudlist=[]\n",
    "STLfilename=[]\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429cd781",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (STL_fnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325120e1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "smean_list,svar_list,stddev_list,max_stress_list,modulus_list,voxellist,pointcloudlist,STLfilename=run_sims (size_voxel_set=64,\n",
    "             threshold=0.9,\n",
    "             sizevoxel =1.,\n",
    "             k_spring= 5.,\n",
    "             r0=3.5,\n",
    "             use_omp = False ,\n",
    "              loc='./STL_collection/',\n",
    "              STL_fnames=STL_fnames,\n",
    "            startjj=9000,                                                                                                 \n",
    "             smean_list=smean_list,\n",
    "            svar_list=svar_list,\n",
    "            stddev_list=stddev_list,\n",
    "            max_stress_list=max_stress_list,\n",
    "            modulus_list=modulus_list,\n",
    "            voxellist=voxellist,\n",
    "            pointcloudlist=pointcloudlist,\n",
    "            STLfilename=STLfilename,       \n",
    "             csv_fname=\"output_results_9000.csv\" ,\n",
    "          LAMMPS_OUT='./LAMMPS_OUT_9000/',\n",
    "          pullsteps=100000,\n",
    "          vspeed=(0, 0, 0.00025),                                                                                       \n",
    "        coord_name='./data_harmonic_9000.coor',\n",
    "       show_on=False,\n",
    "     reorient=True,\n",
    "     scaled=False,\n",
    "     fnameout=\"in_python_FCC_voxel_harmonic_pull_PROCESSED_9000.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95196f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "modulus, max_stress=analyze_plot_stress (fname=f'{LAMMPS_OUT}/sscurve.dat', miniter= 0, maxiter=10 , modulus_dir=3 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0230779",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_dist_data (results, ID='modulus', xl=0, xh=500, bins=100, withline=False, plot_raw=False, norm=True):\n",
    "    modulusdata = results[ID].values\n",
    "\n",
    "    if plot_raw:\n",
    "        plt.plot (modulusdata,  'bo-',label=f'{ID} data')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "    nf=1    \n",
    "    if norm:\n",
    "        nf=statistics.pstdev(modulusdata)\n",
    "        modulusdata=modulusdata/nf\n",
    "        print (\"Data NORMALIZED BY Standart Dev: \", nf)\n",
    "        \n",
    "    if withline==False:\n",
    "        \n",
    "        fig_handle = sns.distplot(modulusdata,bins=bins,kde=False,  \n",
    "                                      rug=False,norm_hist=False,axlabel= ID )\n",
    "        fig = fig_handle.get_figure()\n",
    "\n",
    "        fig_handle.set_xlim(xl, xh)\n",
    "\n",
    "        fig.savefig(f'modulus_distribution_{ID}.png',dpi=200)\n",
    "\n",
    "\n",
    "        plt.show()\n",
    "    else:\n",
    "        fig_handle=sns.histplot(x=modulusdata,    discrete=True,stat='density',\n",
    "                 color='darkblue', edgecolor='blue', \n",
    "                 kde=True, kde_kws={'cut': 5}, line_kws={'linewidth': 2}, bins=bins,)\n",
    "        fig_handle.set_xlim(xl, xh)\n",
    "        fig_handle.set_xlabel(ID)#, fontsize = 8)\n",
    "        fig_handle.set_ylabel(\"Density\")#, fontsize = 20)\n",
    "        fig.savefig(f'modulus_distribution_fit_{ID}.png',dpi=200)\n",
    "\n",
    "        plt.show()\n",
    "        \n",
    "    d_array = np.array(modulusdata)\n",
    "    index = np.argmax(d_array)\n",
    "    trueindex=re.sub(r\"\\D\", \"\", results['voxel_file'][index])\n",
    "    fname=results['voxel_file'][index]\n",
    "    \n",
    "    index_l = np.argmin(d_array)\n",
    "    trueindex_l=re.sub(r\"\\D\", \"\", results['voxel_file'][index_l])\n",
    "    fname_l=results['voxel_file'][index_l]\n",
    "    \n",
    "    print(f\"Highest {ID} value at: {index} = {d_array[index]} : {results['voxel_file'][index]}, True index={trueindex}\" )\n",
    "    #print (str(results.columns.values))\n",
    "    print (f\"{results['modulus'][index]} {results['max_stress'][index]} {results['stress_mean'][index]}\\\n",
    "    {results['s_stddev'][index]} {results['s_var'][index]}: {results['voxel_file'][index]}\")\n",
    "\n",
    " \n",
    "    \n",
    "    print(f\"Lowest {ID} value at: {index_l} = {d_array[index_l]} : {results['voxel_file'][index_l]}, True index={trueindex_l}\" )\n",
    "    #print (results.columns.values)\n",
    "    print (f\"{results['modulus'][index_l]} {results['max_stress'][index_l]} {results['stress_mean'][index_l]}\\\n",
    "    {results['s_stddev'][index_l]} {results['s_var'][index_l]}: {results['voxel_file'][index_l]}\")\n",
    "\n",
    "    return index, d_array[index], index_l, d_array[index_l], fname, fname_l\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd6f117",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path=f'{LAMMPS_OUT}/output_results_averaged.csv'#'pdb_format_update_4_30_picked_318.dat'\n",
    "results=pd.read_csv(file_path)\n",
    "\n",
    "results.drop(results[results['modulus'] < 0.1].index, inplace = True)\n",
    "results.drop(results[results['max_stress'] < 0.1 ].index, inplace = True)\n",
    "\n",
    "results=results.reset_index(drop=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1935b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "_,_,_,_,fname, fname_l=plot_dist_data (results,ID='modulus',xl=0, xh=7, bins=100, withline=False, plot_raw=False ,norm=True)\n",
    "_,_,_,_,fname, fname_l=plot_dist_data (results,ID='max_stress',xl=0, xh=8, bins=100,withline=False, plot_raw=False,norm=True)\n",
    "_,_,_,_,fname, fname_l=plot_dist_data (results,ID='stress_mean',xl=0, xh= 3, bins=500,withline=False, plot_raw=False,norm=True)\n",
    "_,_,_,_,fname, fname_l=plot_dist_data (results,ID='s_stddev',xl=0, xh= 2, bins=700,withline=False, plot_raw=False,norm=True)\n",
    "_,_,_,_,fname, fname_l=plot_dist_data (results,ID='s_var',xl=0, xh= .2, bins=5000,withline=False, plot_raw=False,norm=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
