{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7eecaa05-795c-4aad-863c-a01179e6e1c9",
   "metadata": {},
   "source": [
    "# MolShapeGAN\n",
    "\n",
    "## Generative multiscale analysis of de novo proteome-inspired molecular structures and nanomechanical optimization using a VoxelPerceiver transformer model\n",
    "\n",
    "Zhenze Yang, Yu-Chuan Hsu, Markus J. Buehler, \"Generative multiscale analysis of de novo proteome-inspired molecular structures and nanomechanical optimization using a VoxelPerceiver transformer model,\" Journal of the Mechanics and Physics of Solids, Volume 170, January 2023, 105098.\n",
    "\n",
    "mbuehler@MIT.EDU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4d5b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import optim\n",
    "from torch import nn\n",
    "from collections import OrderedDict\n",
    "from utils import *\n",
    "import os\n",
    " \n",
    "import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import visdom\n",
    "\n",
    "print(\"Torch version:\", torch.__version__) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7afac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "CPUonly=True\n",
    "CPUonly=False\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() \n",
    "                                  else \"cpu\")\n",
    "\n",
    "if CPUonly == True:\n",
    "     print (\"CPU!\")\n",
    "     device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0729fc67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import trimesh  \n",
    "import time, warnings\n",
    "from PIL import Image\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "        \n",
    "def img2vox(loc, end='png', thresh=127, im_sh=False):\n",
    "    vox = []\n",
    "    imgs = sorted(glob.glob(loc+'/*.'+end), key=lambda x: (len(x), x))\n",
    "\n",
    "    print('found',len(imgs),'images.',imgs)\n",
    "    for i in imgs:\n",
    "        new_frame = Image.open(i).convert('RGB').convert('L')\n",
    "        \n",
    "        new_frame =np.array(new_frame)\n",
    "        _, new_frame = cv2.threshold(new_frame,thresh,255,cv2.THRESH_BINARY)\n",
    "        \n",
    "        if im_sh:\n",
    "                plt.imshow(new_frame, interpolation='nearest',cmap=\"hot\")\n",
    "                plt.colorbar()\n",
    "                plt.show()\n",
    "                \n",
    "        vox.append(np.array(new_frame))\n",
    "\n",
    "    return np.array(vox)\n",
    "\n",
    "def TwoDimg23Dvox(img_,maxheight=10, invvv=False, thresh=0, normalize=False,norm_zero=False,clipvalue=0,sat=1,GaussSmoothimage=False, iblur=0, BilatSmoothimage=False, centerrep=0, darea=0, invertresult=False):\n",
    "\n",
    "   vox = []\n",
    "   print (\"Number of images: \", len (img_[:]))  \n",
    "   for imc in range (len(img_[:])):\n",
    "    img=img_[imc]\n",
    "    print (\"Considering image: \", imc)\n",
    "    if GaussSmoothimage==True:\n",
    "        print (\"smoothen using Gaussian Blur...\")\n",
    "        #Applying  blur filter\n",
    "        img = cv2.GaussianBlur(img,(5,5),0)\n",
    "        \n",
    "        for ij in range (iblur):\n",
    "                img = cv2.GaussianBlur(img, (3,3), 10,10)\n",
    "    if BilatSmoothimage==True:\n",
    "        print (\"smoothen using Bilat Blur...\")\n",
    "        #Applying  blur filter\n",
    "        img = cv2.bilateralFilter(img,9,75,75) \n",
    "        for ij in range (iblur):\n",
    "                img = cv2.bilateralFilter(img,9,75,75) \n",
    "\n",
    "    img =np.array(img)\n",
    "    img = np.array(img, dtype = np.float16)\n",
    "\n",
    "    #apply overall threshold - below thresh = 0, creates holes\n",
    "    img[img <thresh] = 0\n",
    "    \n",
    "    if normalize==True:\n",
    "            minval=np.amin(img[img>0])-clipvalue\n",
    "         \n",
    "            if norm_zero: \n",
    "             \n",
    "                img=img-minval\n",
    "              \n",
    "                img=np.clip(img, 0, 255)\n",
    "               \n",
    "                \n",
    "                plt.imshow(img, interpolation='nearest',cmap=\"hot\")\n",
    "                plt.colorbar()\n",
    "                plt.show()\n",
    "                \n",
    "            print ( np.amin(img), np.amax(img))\n",
    "        \n",
    "            img=img/np.amax(img)*255\n",
    "    \n",
    "            \n",
    "    img=img*sat\n",
    "    img[img >255] = 255\n",
    "    \n",
    "    \n",
    "    img = np.array(img, dtype = np.uint8)\n",
    "\n",
    "    if darea>0:\n",
    "        \n",
    "        _, thresh_i = cv2.threshold(img,80,255,cv2.THRESH_BINARY)\n",
    "        plt.imshow(thresh_i, interpolation='nearest',cmap=\"hot\")\n",
    "        plt.colorbar()\n",
    "        plt.show()\n",
    "\n",
    "        cnts = cv2.findContours(thresh_i, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE )\n",
    "        cnts = cnts[0] if len(cnts) == 2 else cnts[1]\n",
    "        for c in cnts:\n",
    "            area = cv2.contourArea(c)\n",
    "           \n",
    "            if area < darea:\n",
    "              \n",
    "                cv2.drawContours(img, [c], -1, (0,0,0), -1)\n",
    " \n",
    "    if invertresult:\n",
    "        img = cv2.bitwise_not(img)\n",
    "    \n",
    "    plt.imshow(img, interpolation='nearest',cmap=\"hot\")\n",
    "    plt.colorbar()\n",
    "    plt.show()\n",
    "   \n",
    "    if invvv==True:\n",
    "   \n",
    "      for ii in range (maxheight):\n",
    "    \n",
    "        threshold=(maxheight-ii)/(maxheight)*255\n",
    "        \n",
    "        z = np.copy(img)\n",
    "        \n",
    "        z[z <threshold] = 0\n",
    "        z[z >0] = 255\n",
    "            \n",
    "        vox.append(z)\n",
    "\n",
    "    if centerrep>0:\n",
    "    \n",
    "        z2 = np.copy(img)\n",
    "\n",
    "        z2[z2 >=0] = 255\n",
    "    \n",
    "        for infg in range( (centerrep)):\n",
    "             vox.append(z2)\n",
    "\n",
    "    for ii in range (maxheight):\n",
    "    \n",
    "        threshold=(ii/maxheight)*255\n",
    "       \n",
    "        z = np.copy(img)\n",
    "        \n",
    "        z[z <threshold] = 0\n",
    "        z[z >0] = 255\n",
    "        \n",
    "        vox.append(z)\n",
    "\n",
    "   return np.array(vox)\n",
    "\n",
    "def TwoDimg23Dvox_BACKUP(img,maxheight=10, invvv=False, thresh=0, normalize=False,sat=1,GaussSmoothimage=False, BilatSmoothimage=False):\n",
    "\n",
    "    if GaussSmoothimage==True:\n",
    "      \n",
    "        #Applying the blur filter\n",
    "        img = cv2.GaussianBlur(img,(5,5),0)\n",
    "     \n",
    "    if BilatSmoothimage==True:\n",
    "        print (\"smoothen using Gaussian Blur...\")\n",
    "    \n",
    "        img = cv2.bilateralFilter(img,9,75,75) \n",
    "        \n",
    "    img =np.array(img)\n",
    "   \n",
    "    img[img <thresh] = 0\n",
    "    \n",
    "    if normalize==True:\n",
    "            \n",
    "            print (\"Normalize...\", np.amin(img), np.amax(img))\n",
    "            img=img-(np.amin(img)   )\n",
    "            img[img <0] = 0\n",
    "    \n",
    "            print (  np.amax(img))\n",
    "            img=img/np.amax(img)*255\n",
    "            \n",
    "    img=img*sat\n",
    "    img[img >255] = 255\n",
    "    \n",
    "    plt.imshow(img, interpolation='nearest',cmap=\"hot\")\n",
    "    plt.colorbar()\n",
    "    plt.show()\n",
    "\n",
    "    vox = []\n",
    "     \n",
    "    if invvv==True:\n",
    "    \n",
    "      for ii in range (maxheight):\n",
    "    \n",
    "        threshold=(maxheight-ii)/(maxheight)*255\n",
    "  \n",
    "        z = np.copy(img)\n",
    "        \n",
    "        z[z <threshold] = 0\n",
    "        z[z >0] = 255\n",
    "            \n",
    "        vox.append(z)\n",
    "\n",
    "    for ii in range (maxheight):\n",
    "    \n",
    "        threshold=(ii/maxheight)*255\n",
    "       \n",
    "        z = np.copy(img)\n",
    "        \n",
    "        z[z <threshold] = 0\n",
    "        z[z >0] = 255\n",
    "    \n",
    "            \n",
    "        vox.append(z)\n",
    "\n",
    "    return np.array(vox)\n",
    "\n",
    "def vox2stl(vox, loc='.', filename='', save=True, smooth=False, smooth_iter=20, stamp=False):\n",
    "    mesh = trimesh.voxel.ops.matrix_to_marching_cubes(vox)\n",
    "\n",
    "    if smooth:\n",
    "         \n",
    "        mesh=  trimesh.smoothing.filter_mut_dif_laplacian(mesh, lamb=0.85, iterations=smooth_iter)\n",
    "        \n",
    "    mesh.rezero()\n",
    "    if save:\n",
    "\n",
    "        from time import strftime\n",
    "        stamp = strftime(\"%m_%d_%H_%M\")\n",
    "        os.makedirs(loc, exist_ok=True)\n",
    "       \n",
    "        exportname=loc+'/'+filename+'.stl'    \n",
    "        mesh.export(exportname)\n",
    "        print(f'save stl model to {exportname}' )\n",
    "        \n",
    "        return exportname\n",
    "\n",
    "# return a vox that vox1 OR vox2 exist (A||B) \n",
    "def union(vox1, vox2): \n",
    "    return np.logical_or(vox1, vox2)\n",
    "\n",
    "# return a vox that EITHER only vox1 OR vox2 exists (A||B-A&&B)\n",
    "def xor(vox1, vox2):\n",
    "    return np.logical_xor(vox1, vox2)\n",
    "\n",
    "# return a vox that both vox1 exists BUT vox2 does not (A-B) \n",
    "def substraction(vox1, vox2):\n",
    "    return np.logical_xor(np.logical_or(vox1, vox2), vox2)\n",
    "\n",
    "# return a vox that vox1 and vox2 BOTH exist (A&&B) \n",
    "def intersection(vox1, vox2):\n",
    "    return np.logical_and(vox1, vox2)\n",
    "\n",
    "# return a vox inverse to the original (B!=A) \n",
    "def inverse(vox):\n",
    "    return np.logical_not(vox)\n",
    "\n",
    "def repeat(vox, repeatance_array):\n",
    "    return np.tile(vox, repeatance_array)*1\n",
    "\n",
    "def vox2img(vox, loc='.', filename=''):\n",
    "    \n",
    "    from time import strftime\n",
    "    stamp = strftime(\"%m_%d_%H_%M\")\n",
    "    os.makedirs(loc+'/'+filename+'_img/', exist_ok=True)\n",
    "    for i in range(vox.shape[0]):\n",
    "        temp_img=vox[i]\n",
    "        plt.imsave(loc+'/'+filename+'_img/'+filename+'_'+stamp+'_'+str(i)+'.png', temp_img, cmap='gray')\n",
    "        from IPython import display\n",
    "        display.clear_output(wait=True)\n",
    "        plt.imshow(temp_img, cmap='gray')    \n",
    "        plt.axis('off')\n",
    "        plt.title(str(i))\n",
    "        plt.show()\n",
    "    \n",
    "    print('save stl model as a stack of images into {}'.format(loc+'/'+filename+'_img/'))\n",
    "\n",
    "def vox2npy(vox, loc='.', filename=''):\n",
    "    from time import strftime\n",
    "    stamp = strftime(\"%m_%d_%H_%M\")\n",
    "    os.makedirs(loc, exist_ok=True)\n",
    "    np.save(loc+'/'+filename+'_'+stamp+'.npy', vox)\n",
    "    print('save stl model as a 3D array to {}'.format(loc+'/'+filename+'_'+stamp+'.npy'))\n",
    "\n",
    "def npy2vox(filename=''):\n",
    "    return np.load(filename)*1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b16bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/xchhuang/simple-pytorch-3dgan\n",
    "class net_G(torch.nn.Module):\n",
    "    def __init__(self, args):\n",
    "        super(net_G, self).__init__()\n",
    "        self.args = args\n",
    "        self.cube_len = cube_len\n",
    "        self.bias = bias\n",
    "        self.z_dim = z_dim\n",
    "        self.f_dim = cube_len\n",
    "\n",
    "        padd = (0, 0, 0)\n",
    "        if self.cube_len == 32:\n",
    "            padd = (1,1,1)\n",
    "\n",
    "        self.layer1 = self.conv_layer(self.z_dim, self.f_dim*8, kernel_size=4, stride=2, padding=padd, bias=self.bias)\n",
    "        self.layer2 = self.conv_layer(self.f_dim*8, self.f_dim*4, kernel_size=4, stride=2, padding=(1, 1, 1), bias=self.bias)\n",
    "        self.layer3 = self.conv_layer(self.f_dim*4, self.f_dim*2, kernel_size=4, stride=2, padding=(1, 1, 1), bias=self.bias)\n",
    "        self.layer5 = self.conv_layer(self.f_dim*2, self.f_dim, kernel_size=4, stride=2, padding=(1, 1, 1), bias=self.bias)\n",
    "        \n",
    "        self.layer6 = torch.nn.Sequential(\n",
    "            torch.nn.ConvTranspose3d(self.f_dim, 1, kernel_size=4, stride=2, bias=self.bias, padding=(1, 1, 1)),\n",
    "            torch.nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def conv_layer(self, input_dim, output_dim, kernel_size=4, stride=2, padding=(1,1,1), bias=False):\n",
    "        layer = torch.nn.Sequential(\n",
    "            torch.nn.ConvTranspose3d(input_dim, output_dim, kernel_size=kernel_size, stride=stride, bias=bias, padding=padding),\n",
    "            torch.nn.BatchNorm3d(output_dim),\n",
    "            torch.nn.ReLU(True)\n",
    "         \n",
    "        )\n",
    "        return layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = x.view(-1, self.z_dim, 1, 1, 1)\n",
    "        # print(out.size())  # torch.Size([32, 200, 1, 1, 1])\n",
    "        out = self.layer1(out)\n",
    "        # print(out.size())  # torch.Size([32, 256, 2, 2, 2])\n",
    "        out = self.layer2(out)\n",
    "        # print(out.size())  # torch.Size([32, 128, 4, 4, 4])\n",
    "        out = self.layer3(out)\n",
    "        # print(out.size())  # torch.Size([32, 64, 8, 8, 8])\n",
    "        #out = self.layer4(out)\n",
    "        # print(out.size())  # torch.Size([32, 32, 16, 16, 16])\n",
    "        out = self.layer5(out)\n",
    "        # print(out.size())  # torch.Size([32, 1, 32, 32, 32])\n",
    "        out = self.layer6(out)\n",
    "        #print(out.size())  # torch.Size([32, 1, 32, 32, 32])\n",
    "        out = torch.squeeze(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class net_D(torch.nn.Module):\n",
    "    def __init__(self, args):\n",
    "        super(net_D, self).__init__()\n",
    "        self.args = args\n",
    "        self.cube_len = cube_len\n",
    "        self.leak_value = leak_value\n",
    "        self.bias = bias\n",
    "\n",
    "        padd = (0,0,0)\n",
    "        if self.cube_len == 32:\n",
    "            padd = (1,1,1)\n",
    "\n",
    "        self.f_dim = cube_len\n",
    "\n",
    "        self.layer1 = self.conv_layer(1, self.f_dim, kernel_size=4, stride=2, padding=(1,1,1), bias=self.bias)\n",
    "        self.layer2 = self.conv_layer(self.f_dim, self.f_dim*2, kernel_size=4, stride=2, padding=(1,1,1), bias=self.bias)\n",
    "        self.layer4 = self.conv_layer(self.f_dim*2, self.f_dim*4, kernel_size=4, stride=2, padding=(1,1,1), bias=self.bias)\n",
    "        self.layer5 = self.conv_layer(self.f_dim*4, self.f_dim*8, kernel_size=4, stride=2, padding=(1,1,1), bias=self.bias)\n",
    "\n",
    "        self.layer6 = torch.nn.Sequential(\n",
    "            torch.nn.Conv3d(self.f_dim*8, 1, kernel_size=4, stride=2, bias=self.bias, padding=padd),\n",
    "            torch.nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def conv_layer(self, input_dim, output_dim, kernel_size=4, stride=2, padding=(1,1,1), bias=False):\n",
    "        layer = torch.nn.Sequential(\n",
    "            torch.nn.Conv3d(input_dim, output_dim, kernel_size=kernel_size, stride=stride, bias=bias, padding=padding),\n",
    "            torch.nn.BatchNorm3d(output_dim),\n",
    "            torch.nn.LeakyReLU(self.leak_value, inplace=True)\n",
    "        )\n",
    "        return layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        # out = torch.unsqueeze(x, dim=1)\n",
    "        out = x.view(-1, 1, self.cube_len, self.cube_len, self.cube_len)\n",
    "        # print(out.size()) # torch.Size([32, 1, 32, 32, 32])\n",
    "        out = self.layer1(out)\n",
    "        # print(out.size())  # torch.Size([32, 32, 16, 16, 16])\n",
    "        out = self.layer2(out)\n",
    "        # print(out.size())  # torch.Size([32, 64, 8, 8, 8])\n",
    "        #out = self.layer3(out)\n",
    "        # print(out.size())  # torch.Size([32, 128, 4, 4, 4])\n",
    "        out = self.layer4(out)\n",
    "        # print(out.size())  # torch.Size([32, 256, 2, 2, 2])\n",
    "        # out = out.view(-1, 256*2*2*2)\n",
    "        # print (out.size())\n",
    "        out = self.layer5(out)\n",
    "        # print(out.size())  # torch.Size([32, 1, 1, 1, 1])\n",
    "        out = self.layer6(out)\n",
    "        #print(out.size())  # torch.Size([32, 1, 1, 1, 1])\n",
    "        out = torch.squeeze(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8749ffba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from simple_3dviz import Mesh\n",
    "from simple_3dviz.window import show\n",
    "from simple_3dviz.utils import render\n",
    "from simple_3dviz.behaviours.io import SaveFrames\n",
    "from simple_3dviz.behaviours.movements import CameraTrajectory\n",
    "from simple_3dviz.behaviours.trajectory import Circle\n",
    "from simple_3dviz.behaviours.misc import LightToCamera\n",
    "\n",
    "def tester(args, threshold=0.5, startnum=0):\n",
    "\n",
    "    model_name + '/' + args.logs + '/test_outputs'\n",
    "    if not os.path.exists(image_saved_path):\n",
    "        os.makedirs(image_saved_path)\n",
    "\n",
    "    if args.use_visdom:\n",
    "        vis = visdom.Visdom()\n",
    "\n",
    "    save_file_path = output_dir + '/' + args.model_name\n",
    "    pretrained_file_path_G = save_file_path + '/' + args.logs + '/models/G.pth'\n",
    "    pretrained_file_path_D = save_file_path + '/' + args.logs + '/models/D.pth'\n",
    "\n",
    "    print(pretrained_file_path_G)\n",
    "\n",
    "    D = net_D(args)\n",
    "    G = net_G(args)\n",
    "\n",
    "    if not torch.cuda.is_available():\n",
    "        G.load_state_dict(torch.load(pretrained_file_path_G, map_location={'cuda:0': 'cpu'}))\n",
    "        D.load_state_dict(torch.load(pretrained_file_path_D, map_location={'cuda:0': 'cpu'}))\n",
    "    else:\n",
    "        G.load_state_dict(torch.load(pretrained_file_path_G))\n",
    "        D.load_state_dict(torch.load(pretrained_file_path_D, map_location={'cuda:0': 'cpu'}))\n",
    "\n",
    "    print('visualizing model')\n",
    "\n",
    "    G.to(device)\n",
    "    D.to(device)\n",
    "    G.eval()\n",
    "    D.eval()\n",
    "\n",
    "    N = num_examples\n",
    "\n",
    "    for i in range(N):\n",
    "     \n",
    "        z = generateZ(args, 1)\n",
    "\n",
    "        fake = G(z)\n",
    "        samples = fake.unsqueeze(dim=0).detach().cpu().numpy()\n",
    "      \n",
    "        y_prob = D(fake)\n",
    "        y_real = torch.ones_like(y_prob)\n",
    "\n",
    "        # visualization\n",
    "        if not args.use_visdom:\n",
    "            _=SavePloat_Voxels(samples, image_saved_path, 'tester_' + str(i+startnum), threshold)  # norm_\n",
    "        else:\n",
    "            plotVoxelVisdom(samples[0, :], vis, \"tester_\" + str(i+startnum))\n",
    "            \n",
    "        if args.save_np:\n",
    "            print (\"Save numpy file(s)...: \")\n",
    "           \n",
    "            for iii in range (samples.shape[0]):\n",
    "                f=image_saved_path+f'/np_vox_{i+startnum:04d}_{iii:04d}'\n",
    "                print (\"save \", f)\n",
    "             \n",
    "                np.save(f, samples[iii,:,:,:])\n",
    "            \n",
    "def tester_interpolate(args, threshold=0.5, z1=None, z2=None, steps=5):\n",
    "    print('Evaluation Mode...')\n",
    "\n",
    "    image_saved_path = output_dir + '/' + args.model_name + '/' + args.logs + '/test_outputs'\n",
    "    if not os.path.exists(image_saved_path):\n",
    "        os.makedirs(image_saved_path)\n",
    "\n",
    "    if args.use_visdom:\n",
    "        vis = visdom.Visdom()\n",
    "\n",
    "    save_file_path = output_dir + '/' + args.model_name\n",
    "    pretrained_file_path_G = save_file_path + '/' + args.logs + '/models/G.pth'\n",
    "    pretrained_file_path_D = save_file_path + '/' + args.logs + '/models/D.pth'\n",
    "\n",
    "    print(pretrained_file_path_G)\n",
    "\n",
    "    D = net_D(args)\n",
    "    G = net_G(args)\n",
    "\n",
    "    if not torch.cuda.is_available():\n",
    "        G.load_state_dict(torch.load(pretrained_file_path_G, map_location={'cuda:0': 'cpu'}))\n",
    "        D.load_state_dict(torch.load(pretrained_file_path_D, map_location={'cuda:0': 'cpu'}))\n",
    "    else:\n",
    "        G.load_state_dict(torch.load(pretrained_file_path_G))\n",
    "        D.load_state_dict(torch.load(pretrained_file_path_D, map_location={'cuda:0': 'cpu'}))\n",
    "\n",
    "    print('visualizing model')\n",
    "\n",
    "    G.to(device)\n",
    "    D.to(device)\n",
    "    G.eval()\n",
    "    D.eval()\n",
    "\n",
    "    if z1 == None:\n",
    "        z1 = generateZ(args, 1)\n",
    "    if z2 == None:\n",
    "        z2 = generateZ(args, 1)\n",
    "    \n",
    "    for i in range(steps):\n",
    "      \n",
    "        z=z1+ (z2-z1)*(i/(steps-1))\n",
    "     \n",
    "        fake = G(z)\n",
    "        samples = fake.unsqueeze(dim=0).detach().cpu().numpy()\n",
    "        \n",
    "        y_prob = D(fake)\n",
    "        y_real = torch.ones_like(y_prob)\n",
    "       \n",
    "        # visualization\n",
    "        if not args.use_visdom:\n",
    "            fname=SavePloat_Voxels(samples, image_saved_path, 'tester_interpol_' + str(i), threshold)  # norm_\n",
    "            fname_n=image_saved_path+f'/{i:04d}.png' \n",
    "            print (\"New name: \", fname_n)\n",
    "            os.rename(fname, fname_n)\n",
    "        if args.save_np:\n",
    "            print (\"Save numpy file(s)...: \")\n",
    "          \n",
    "            for iii in range (samples.shape[0]):\n",
    "                f=image_saved_path+f'/np_vox_{i:04d}_{iii:04d}'\n",
    "                print (\"save \", f)\n",
    "            \n",
    "                np.save(f, samples[iii,:,:,:] )\n",
    "                \n",
    "        if args.use_3dviz:\n",
    "            \n",
    "            render(Mesh.from_voxel_grid(voxels=samples[0,:] > threshold,  colors=[0.4,0.4,0.8], sizes=(.006,.006,.006)),\n",
    "               behaviours=[\n",
    "                    #ctrj,\n",
    "                    LightToCamera(),\n",
    "                    SaveFrames(image_saved_path+f'/3dvis_{i:04d}.png')#, every_n=5)\n",
    "               ],\n",
    "                   size=(1024,1024),\n",
    "                   background=(1.0, 1.0, 1.0, 1.0),\n",
    "               n_frames=1,\n",
    "               camera_position=(.8,.8,.8), camera_target=(0., 0, 0),\n",
    "               light=(1, 5, 5)\n",
    "        )\n",
    "\n",
    "        else:\n",
    "            plotVoxelVisdom(samples[0, :], vis, \"tester_interpol_\" + str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1e6ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import optim\n",
    "from torch import nn\n",
    "from utils import *\n",
    "import os\n",
    "\n",
    "# added\n",
    "import datetime\n",
    "import time\n",
    "from tensorboardX import SummaryWriter\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import params\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def save_train_log(writer, loss_D, loss_G, itr):\n",
    "    scalar_info = {}\n",
    "    for key, value in loss_G.items():\n",
    "        scalar_info['train_loss_G/' + key] = value\n",
    "\n",
    "    for key, value in loss_D.items():\n",
    "        scalar_info['train_loss_D/' + key] = value\n",
    "\n",
    "    for tag, value in scalar_info.items():\n",
    "        writer.add_scalar(tag, value, itr)\n",
    "\n",
    "\n",
    "def save_val_log(writer, loss_D, loss_G, itr):\n",
    "    scalar_info = {}\n",
    "    for key, value in loss_G.items():\n",
    "        scalar_info['val_loss_G/' + key] = value\n",
    "\n",
    "    for key, value in loss_D.items():\n",
    "        scalar_info['val_loss_D/' + key] = value\n",
    "\n",
    "    for tag, value in scalar_info.items():\n",
    "        writer.add_scalar(tag, value, itr)\n",
    "\n",
    "\n",
    "def trainer(args,train_dset_loaders, restart=False):\n",
    "   \n",
    "    save_file_path = output_dir + '/' + args.model_name\n",
    "    print(save_file_path)  # ../outputs/dcgan\n",
    "    \n",
    "    if not os.path.exists(save_file_path):\n",
    "        os.makedirs(save_file_path)\n",
    "\n",
    "    if args.logs:\n",
    "        print (\"SETTING UP LOGS...\")\n",
    "        model_uid = datetime.datetime.now().strftime(\"%d-%m-%Y-%H-%M-%S\")\n",
    "        #writer = SummaryWriter(output_dir+'/'+args.model_name+'/'+model_uid+'_'+args.logs+'/logs')\n",
    "        writer = SummaryWriter(output_dir + '/' + args.model_name + '/' + args.logs + '/logs')\n",
    "\n",
    "        image_saved_path = output_dir + '/' + args.model_name + '/' + args.logs + '/images'\n",
    "        model_saved_path = output_dir + '/' + args.model_name + '/' + args.logs + '/models'\n",
    "\n",
    "        if not os.path.exists(image_saved_path):\n",
    "            os.makedirs(image_saved_path)\n",
    "        if not os.path.exists(model_saved_path):\n",
    "            os.makedirs(model_saved_path)\n",
    "\n",
    "    # model define\n",
    "    if restart==False:\n",
    "        D = net_D(args)\n",
    "        G = net_G(args)\n",
    "    if restart:\n",
    "        print (\"Restart from existing neural net....\")\n",
    "        \n",
    "    # print total number of parameters in a model\n",
    "    x = sum(p.numel() for p in G.parameters() if p.requires_grad)\n",
    "    x = sum(p.numel() for p in D.parameters() if p.requires_grad)\n",
    "    \n",
    "    D_solver = optim.Adam(D.parameters(), lr=d_lr, betas=beta)\n",
    "    # D_solver = optim.SGD(D.parameters(), lr=args.d_lr, momentum=0.9)\n",
    "    G_solver = optim.Adam(G.parameters(), lr=g_lr, betas=beta)\n",
    "\n",
    "    D.to(device)\n",
    "    G.to(device)\n",
    "\n",
    "    criterion_D = nn.MSELoss()\n",
    "\n",
    "    criterion_G = nn.L1Loss()\n",
    "\n",
    "    itr_val = -1\n",
    "    itr_train = -1\n",
    "    \n",
    "    print (\"START TRAINING....\")\n",
    "    for epoch in range(epochs):\n",
    "        start = time.time()\n",
    "        for phase in ['train']:\n",
    "            if phase == 'train':\n",
    "                # if args.lrsh:\n",
    "                #     D_scheduler.step()\n",
    "                D.train()\n",
    "                G.train()\n",
    "            else:\n",
    "                D.eval()\n",
    "                G.eval()\n",
    "\n",
    "            running_loss_G = 0.0\n",
    "            running_loss_D = 0.0\n",
    "            running_loss_adv_G = 0.0\n",
    "            \n",
    "            for i, X in enumerate(train_dset_loaders):\n",
    "                if phase == 'train':\n",
    "                    itr_train += 1\n",
    "\n",
    "                X = X.to(device)\n",
    "              \n",
    "                batch = X.size()[0]\n",
    "\n",
    "                Z = generateZ(args, batch)\n",
    "              \n",
    "                d_real = D(X)\n",
    "\n",
    "                fake = G(Z)\n",
    "                \n",
    "                d_fake = D(fake)\n",
    "\n",
    "                real_labels = torch.ones_like(d_real).to(device)\n",
    "                fake_labels = torch.zeros_like(d_fake).to(device)\n",
    "               \n",
    "                if soft_label:\n",
    "                    real_labels = torch.Tensor(batch).uniform_(0.7, 1.2).to(device)\n",
    "                    fake_labels = torch.Tensor(batch).uniform_(0, 0.3).to(device)\n",
    "\n",
    "                d_real_loss = criterion_D(d_real, real_labels)\n",
    "\n",
    "                d_fake_loss = criterion_D(d_fake, fake_labels)\n",
    "\n",
    "                d_loss = d_real_loss + d_fake_loss\n",
    "\n",
    "                # no deleted\n",
    "                d_real_acu = torch.ge(d_real.squeeze(), 0.5).float()\n",
    "                d_fake_acu = torch.le(d_fake.squeeze(), 0.5).float()\n",
    "                d_total_acu = torch.mean(torch.cat((d_real_acu, d_fake_acu), 0))\n",
    "\n",
    "                if d_total_acu < d_thresh:\n",
    "                    D.zero_grad()\n",
    "                    d_loss.backward()\n",
    "                    D_solver.step()\n",
    "\n",
    "                # =============== Train the generator ===============#\n",
    "\n",
    "                Z = generateZ(args, batch)\n",
    "\n",
    "                fake = G(Z)  # generated fake: 0-1, X: 0/1\n",
    "                d_fake = D(fake)\n",
    "\n",
    "                adv_g_loss = criterion_D(d_fake, real_labels)\n",
    "                recon_g_loss = criterion_G(fake, X)\n",
    "                g_loss = adv_g_loss\n",
    "\n",
    "                if args.local_test:\n",
    "                    print('Iteration-{} , D(x) : {:.4}, D(G(x)) : {:.4}'.format(itr_train, d_loss.item(),\n",
    "                                                                                adv_g_loss.item()))\n",
    "\n",
    "                D.zero_grad()\n",
    "                G.zero_grad()\n",
    "                g_loss.backward()\n",
    "                G_solver.step()\n",
    "\n",
    "                # =============== logging each 10 iterations ===============#\n",
    "\n",
    "                running_loss_G += recon_g_loss.item() * X.size(0)\n",
    "                running_loss_D += d_loss.item() * X.size(0)\n",
    "                running_loss_adv_G += adv_g_loss.item() * X.size(0)\n",
    "\n",
    "                if args.logs:\n",
    "                    loss_G = {\n",
    "                        'adv_loss_G': adv_g_loss,\n",
    "                        'recon_loss_G': recon_g_loss,\n",
    "                    }\n",
    "\n",
    "                    loss_D = {\n",
    "                        'adv_real_loss_D': d_real_loss,\n",
    "                        'adv_fake_loss_D': d_fake_loss,\n",
    "                    }\n",
    "\n",
    "                    if itr_train % 10 == 0 and phase == 'train':\n",
    "                        print(\".\", end=\"\")\n",
    "                        save_train_log(writer, loss_D, loss_G, itr_train)\n",
    "                        \n",
    "            # =============== each epoch save model or save image ===============#\n",
    "            epoch_loss_G = running_loss_G# \n",
    "            epoch_loss_D = running_loss_D#  \n",
    "            epoch_loss_adv_G = running_loss_adv_G  \n",
    "\n",
    "            end = time.time()\n",
    "            epoch_time = end - start\n",
    "\n",
    "            print('\\nEpoch {}, D(x) : {:.4}, D(G(x)) : {:.4}'.format(epoch, epoch_loss_D, epoch_loss_adv_G))\n",
    "            print('Elapsed Time: {:.4} min'.format(epoch_time / 60.0))\n",
    "\n",
    "            if (epoch + 1) % model_save_step == 0:\n",
    "              \n",
    "                torch.save(G.state_dict(), model_saved_path + '/G.pth')\n",
    "                torch.save(D.state_dict(), model_saved_path + '/D.pth')\n",
    "\n",
    "                samples = fake.cpu().data[:num_examples].squeeze().numpy()\n",
    "\n",
    "                _=SavePloat_Voxels(samples, image_saved_path, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de27fee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d00c093",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.ndimage as nd\n",
    "import scipy.io as io\n",
    "import matplotlib\n",
    "import params\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage.measure as sk\n",
    "from mpl_toolkits import mplot3d\n",
    "import matplotlib.gridspec as gridspec\n",
    "import numpy as np\n",
    "from torch.utils import data\n",
    "from torch.autograd import Variable\n",
    "import torch\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "def getVoxelFromMat(path, cube_len=64,pr_info=False, numpyfile=False):\n",
    "    \n",
    "    if numpyfile: #load numpy file...\n",
    "        voxels=np.load(path)\n",
    "        voxels = nd.zoom(voxels, (.5, .5, .5), mode='constant', order=0)\n",
    "    \n",
    "    if numpyfile==False:\n",
    "\n",
    "        if cube_len == 32:\n",
    "            voxels = io.loadmat(path)[Instance_name] # 30x30x30\n",
    "            if pr_info:\n",
    "                print ('Raw: ', voxels.shape)\n",
    "            voxels = np.pad(voxels, (1, 1), 'constant', constant_values=(0, 0))\n",
    "\n",
    "        else:\n",
    "            voxels = io.loadmat(path)[Instance_name] # 30x30x30\n",
    "            if pr_info:\n",
    "                print ('Raw: ', voxels.shape)\n",
    "\n",
    "            voxels = np.pad(voxels, (1, 1), 'constant', constant_values=(0, 0))\n",
    "            voxels = nd.zoom(voxels, (2, 2, 2), mode='constant', order=0)\n",
    "            \n",
    "        if pr_info:\n",
    "            print (\"Final shape: \", voxels.shape)\n",
    "    return voxels\n",
    " \n",
    "\n",
    "\n",
    "def getVFByMarchingCubes(voxels, threshold=0.5):\n",
    "    v, f, _, _  = sk.marching_cubes(voxels, level=threshold)\n",
    "    return v, f\n",
    "\n",
    "\n",
    "def plotVoxelVisdom(voxels, visdom, title):\n",
    "    v, f = getVFByMarchingCubes(voxels)\n",
    "    visdom.mesh(X=v, Y=f, opts=dict(opacity=0.5, title=title))\n",
    "\n",
    "\n",
    "def SavePloat_Voxels(voxels, path, iteration, threshold=.5, name=''):\n",
    "    print (\"Generate \", num_examples, )\n",
    "    \n",
    "    if save_STL:\n",
    "        voxels_clean=np.copy(voxels)\n",
    "        for ii, sample in enumerate(voxels_clean[:num_examples]):\n",
    "          \n",
    "            sample[sample > threshold] = 1\n",
    "            sample[sample <= threshold] = 0\n",
    "            \n",
    "            vox2stl(sample, loc=path, filename=f'{name}_voxel_{ii}_{iteration}', save=True, smooth=smooth_STL, smooth_iter=20)\n",
    "\n",
    "    voxels = voxels[:num_examples].__ge__(threshold)\n",
    "    fig = plt.figure(figsize=(32, 16))\n",
    "    gs = gridspec.GridSpec(2, 4)\n",
    "    gs.update(wspace=0.05, hspace=0.05)\n",
    "\n",
    "    for i, sample in enumerate(voxels):\n",
    "        x, y, z = sample.nonzero() #returns indixes or coordinates of all nonzero entries...\n",
    "        ax = plt.subplot(gs[i], projection='3d')\n",
    "        ax.scatter(x, y, z, zdir='z', c='red', marker='s', s=2)\n",
    "        ax.set_xticklabels([])\n",
    "        ax.set_yticklabels([])\n",
    "        \n",
    "        ax.set_xlim((0,cube_len))\n",
    "        ax.set_ylim((0,cube_len))\n",
    "        ax.set_zlim((0,cube_len))\n",
    "     \n",
    "    fname=path +f'/{name}_'+ '{}.png'.format(str(iteration).zfill(4))\n",
    "    plt.savefig(fname, bbox_inches='tight')\n",
    "  \n",
    "    plt.close()\n",
    "    \n",
    "    return fname\n",
    "\n",
    "\n",
    "class ShapeNetDataset(data.Dataset):\n",
    "\n",
    "    def __init__(self, root, args, train_or_val=\"train\", numpyfile=False):\n",
    "        \n",
    "        \n",
    "        self.root = root\n",
    "        self.listdir = os.listdir(self.root)\n",
    "        \n",
    "        self.numpyfile=numpyfile\n",
    "       \n",
    "        data_size = len(self.listdir)\n",
    "        self.listdir = self.listdir[0:int(data_size)]\n",
    "        \n",
    "        print ('Total data size =', len(self.listdir))\n",
    "        self.args = args\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        with open(self.root + self.listdir[index], \"rb\") as f:\n",
    "            \n",
    "            volume = np.asarray(getVoxelFromMat(f, cube_len, numpyfile=self.numpyfile), dtype=np.float32)\n",
    "           \n",
    "        return torch.FloatTensor(volume)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.listdir)\n",
    "\n",
    "def generateZ(args, batch):\n",
    "\n",
    "    if z_dis == \"norm\":\n",
    "        Z = torch.Tensor(batch, z_dim).normal_(0, 0.33).to(device)\n",
    "    elif z_dis == \"uni\":\n",
    "        Z = torch.randn(batch, z_dim).to(device).to(device)\n",
    "    else:\n",
    "        print(\"z_dist is not normal or uniform\")\n",
    "\n",
    "    return Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c312bbb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def str2bool(v):\n",
    "    if v.lower() in ('yes', 'true', 't', 'y', '1'):\n",
    "        return True\n",
    "    elif v.lower() in ('no', 'false', 'f', 'n', '0'):\n",
    "        return False\n",
    "    else:\n",
    "        raise argparse.ArgumentTypeError('Boolean value expected.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83bd9dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_params():\n",
    "    l = 16\n",
    "    print(l * '*' + 'hyper-parameters' + l * '*')\n",
    "\n",
    "    print('epochs =', epochs)\n",
    "    print('batch_size =', batch_size)\n",
    "    print('soft_labels =', soft_label)\n",
    "    print('adv_weight =', adv_weight)\n",
    "    print('d_thresh =', d_thresh)\n",
    "    print('z_dim =', z_dim)\n",
    "    print('z_dis =', z_dis)\n",
    "    print('model_images_save_step =', model_save_step)\n",
    "    print('data =', model_dir)\n",
    "    print('device =', device)\n",
    "    print('g_lr =', g_lr)\n",
    "    print('d_lr =', d_lr)\n",
    "    print('cube_len =', cube_len)\n",
    "    print('leak_value =', leak_value)\n",
    "    print('bias =', bias)\n",
    "\n",
    "    print(l * '*' + 'hyper-parameters' + l * '*')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e96d090e-025e-4a0f-9be1-c0abf99b5145",
   "metadata": {},
   "source": [
    "### Set up and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17c7f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "epochs = 500\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "soft_label = False\n",
    "adv_weight = 0\n",
    "d_thresh = 0.8\n",
    "z_dim = 512\n",
    "z_dis = \"norm\"\n",
    "model_save_step = 1\n",
    "g_lr = 0.0025\n",
    "d_lr = 0.00001\n",
    "beta = (0.5, 0.999)\n",
    "cube_len = 64\n",
    "leak_value = 0.2\n",
    "bias = False\n",
    "Instance_name='instance' #original chair dataset\n",
    "Instance_name='Volume'  #data in VOXELDATA\n",
    "smooth_STL=False\n",
    "\n",
    "save_STL=False\n",
    "\n",
    "num_examples =8\n",
    "model_dir= './np_voxels_proteins_128x128x128_ALLPDB/'\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "# loggings parameters\n",
    "parser.add_argument('--logs', type=str, default='first_test', help='logs by tensorboardX')\n",
    "parser.add_argument('--local_test', type=str2bool, default=False, help='local test verbose')\n",
    "parser.add_argument('--model_name', type=str, default=\"dcgan\", help='model name for saving')\n",
    "parser.add_argument('--output_dir', type=str, default=\"output\", help='output_dir')\n",
    "parser.add_argument('--test', type=str2bool, default=False, help='call tester.py')\n",
    "parser.add_argument('--use_visdom', type=str2bool, default=False, help='visualization by visdom')\n",
    "parser.add_argument('--use_3dviz', type=str2bool, default=False, help='visualization by 3dviz')\n",
    "parser.add_argument('--save_np', type=str2bool, default=False, help='save voxel files as npy')\n",
    "\n",
    "print_params()\n",
    "\n",
    "args = parser.parse_args(\"--model_name PMMD_3DGAN --output_dir output --use_3dviz True\".split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfac055c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "import pyvista as pv\n",
    "\n",
    "def plot_single_mat (matname='./volumetric_data/chair/30/train/chair_000000200_12.mat',cube_len=32, \n",
    "                     numpyfile=False, savepath='./', name='', ID=''):\n",
    "\n",
    "    voxel=getVoxelFromMat(matname, cube_len=cube_len,pr_info=True, numpyfile=numpyfile)\n",
    "    voxel_exp=np.expand_dims(voxel, 0) \n",
    "    \n",
    "    fname=SavePloat_Voxels(voxel_exp, savepath, iteration=0, name=name) \n",
    "   \n",
    "    img = Image.open(fname)\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "   \n",
    "    plt.show()\n",
    "    \n",
    "    filename=f'{matname}_STL_.stl'\n",
    "    from time import strftime\n",
    "    exportname=vox2stl(voxel, loc='./', filename=filename, save=True, smooth=True, smooth_iter=20)\n",
    "    print (exportname)\n",
    "    mesh = pv.read(exportname)\n",
    "    pngname=  strftime(\"./%m_%d_%H_%M\")+'png'\n",
    "    cpos = mesh.plot(  show_edges=False, color=True, screenshot=f\"{ID}_{pngname}\", \n",
    "                     background='white', show_axes=False, parallel_projection=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df48df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Instance_name=''  \n",
    "\n",
    "data_dir = './PyUUL - protein to point cloud/pyuul/'\n",
    "model_dir = './np_voxels_proteins_128x128x128_ALLPDB/'  # change it to train on other data models\n",
    "\n",
    "output_dir = './outputs'\n",
    "cube_len = 64\n",
    "batch_size = 128\n",
    "num_examples =8\n",
    "\n",
    "dsets_path = data_dir + model_dir  \n",
    "\n",
    "train_dsets = ShapeNetDataset(dsets_path, args, \"train\",  numpyfile=True)\n",
    "train_dset_loaders = torch.utils.data.DataLoader(train_dsets, batch_size=batch_size, shuffle=True)#,num_workers=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b879d02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up trainer\n",
    "\n",
    "args = parser.parse_args(\"--model_name PMMD_PROTEIN_64_ALLPDB_30K --output_dir output\".split())\n",
    "\n",
    "trainer(args,train_dset_loaders, restart=False  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41810d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = parser.parse_args(\"--model_name PMMD_PROTEIN_64_ALLPDB_30K --output_dir output_10000 --use_visdom False --test True --save_np True\".split())\n",
    "print (args)\n",
    " \n",
    "cube_len = 64\n",
    "\n",
    "smooth_STL=True\n",
    "num_examples =9000\n",
    "save_STL=True\n",
    "print_params()\n",
    "tester(args, threshold=.1, startnum=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c332b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate two z1 z2 and interpolate between them\n",
    "\n",
    "args = parser.parse_args(\"--model_name PMMD_PROTEIN_64_ALLPDB_30K --output_dir output --use_visdom False --test True\".split())\n",
    "print (args)\n",
    " \n",
    "cube_len = 64\n",
    "\n",
    "smooth_STL=True\n",
    " \n",
    "save_STL=True\n",
    "print_params()\n",
    "tester_interpolate(args, threshold=.1, steps=20)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
